{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2. Seq2Seq LSTM Model - Translation_with_prediction_Attention.ipynb",
      "provenance": []
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JoJPolOgWGG4"
      },
      "source": [
        "### Load tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zlt_1eHPWGG6"
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VzxABbMJWGG-"
      },
      "source": [
        "### Read the data\n",
        "<font size=\"2\">Data for this exercise can be downloaded from http://www.manythings.org/anki/</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ommjMLuF75Dk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3b214e5-961c-4790-d9bf-e7ea9250d7b6"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1vDoJM0zWGG_"
      },
      "source": [
        "#You can use wget to download the file directly\n",
        "!wget http://www.manythings.org/anki/hin-eng.zip --quiet"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A8soXgFrWGHB"
      },
      "source": [
        "import zipfile\n",
        "import io\n",
        "\n",
        "#Read the zip file\n",
        "zf = zipfile.ZipFile('hin-eng.zip', 'r')\n",
        "\n",
        "#Extract data from zip file\n",
        "data = ''\n",
        "with zf.open('hin.txt') as readfile:\n",
        "  for line in io.TextIOWrapper(readfile, 'utf-8'):\n",
        "    data += line"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQFmYMvhWGHE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e53e7193-d1f9-459d-83b3-ebbd1b7e70b1"
      },
      "source": [
        "data[400:500]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' (France) Attribution: tatoeba.org #631038 (Shishir) & #6179121 (fastrizwaan)\\nJump.\\tकूदो.\\tCC-BY 2.0 '"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lx5AWe-0WGHT"
      },
      "source": [
        "\n",
        "### Extract Source and Target Language pairs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mjma2IuuWGHU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d42413d4-84ed-4df6-f3d3-badf856e80db"
      },
      "source": [
        "#Split by newline character\n",
        "data =  data.split('\\n')\n",
        "\n",
        "#Show some Data\n",
        "data[100:105]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['We promised.\\tहमने वादा किया।\\tCC-BY 2.0 (France) Attribution: tatoeba.org #2107668 (CK) & #8876370 (simranbansal)',\n",
              " \"What's this?\\tयह क्या है?\\tCC-BY 2.0 (France) Attribution: tatoeba.org #413821 (CK) & #443158 (minshirui)\",\n",
              " 'Are you sick?\\tक्या तुम बीमार हो?\\tCC-BY 2.0 (France) Attribution: tatoeba.org #434252 (lukaszpp) & #518699 (minshirui)',\n",
              " 'Bring him in.\\tउसको अंदर ले आओ।\\tCC-BY 2.0 (France) Attribution: tatoeba.org #307895 (CK) & #475932 (minshirui)',\n",
              " 'Come with us.\\tहमारे साथ आओ।\\tCC-BY 2.0 (France) Attribution: tatoeba.org #433696 (CK) & #485546 (minshirui)']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Af9jau2XWGHX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46db09a5-d5b3-40b4-9cc2-2089e05367a1"
      },
      "source": [
        "len(data)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2950"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A4ow84XDWGHb"
      },
      "source": [
        "### Separate Source and Target pairs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GTzjK4G6WGHb"
      },
      "source": [
        "encoder_text = [] #Initialize Source language list\n",
        "decoder_text = [] #Initialize Target language list\n",
        "\n",
        "#Iterate over data\n",
        "for line in data:\n",
        "    try:\n",
        "        in_txt, out_txt,_ = line.split('\\t')\n",
        "        encoder_text.append(in_txt)\n",
        "        \n",
        "        # Add tab '<start>' as 'start sequence in target\n",
        "        # And '<end>' as End\n",
        "        decoder_text.append('<start> ' + out_txt + ' <end>')\n",
        "    except:\n",
        "        pass #ignore data which goes into error        "
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4T4HJ3A9WGHd"
      },
      "source": [
        "### Separate Source and Target pairs.."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xyZqwGuvWGHe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a6ca2dc-f250-4043-b3e3-349cb21c8a53"
      },
      "source": [
        "encoder_text[100:105]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['We promised.',\n",
              " \"What's this?\",\n",
              " 'Are you sick?',\n",
              " 'Bring him in.',\n",
              " 'Come with us.']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v2CILOS3WGHg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "299cef23-42ef-4900-bfd6-505084ae03df"
      },
      "source": [
        "decoder_text[100:105]"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<start> हमने वादा किया। <end>',\n",
              " '<start> यह क्या है? <end>',\n",
              " '<start> क्या तुम बीमार हो? <end>',\n",
              " '<start> उसको अंदर ले आओ। <end>',\n",
              " '<start> हमारे साथ आओ। <end>']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CnRP431qWGHj"
      },
      "source": [
        "### Tokenize Source language sentences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ucqBYr4WGHk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c28cd54e-35b2-4569-b667-a12ecd4b40a8"
      },
      "source": [
        "#Tokenizer for source language\n",
        "encoder_t = tf.keras.preprocessing.text.Tokenizer()\n",
        "encoder_t.fit_on_texts(encoder_text) #Fit it on Source sentences\n",
        "encoder_seq = encoder_t.texts_to_sequences(encoder_text) #Convert sentences to numbers \n",
        "encoder_seq[100:105] #Display some converted sentences"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[24, 707], [187, 14], [20, 4, 404], [405, 29, 9], [49, 35, 81]]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zZv-TPVOWGHn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31fca412-cd15-4222-82f9-ab87baab97dc"
      },
      "source": [
        "#Maximum length of sentence\n",
        "max_encoder_seq_length = max([len(txt) for txt in encoder_seq])\n",
        "print('Maximum sentence length for Source language: ', max_encoder_seq_length)\n",
        "\n",
        "#Source language Vocablury\n",
        "encoder_vocab_size = len(encoder_t.word_index)\n",
        "print('Source language vocablury size: ', encoder_vocab_size)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Maximum sentence length for Source language:  22\n",
            "Source language vocablury size:  2432\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BeASC50tWGHr"
      },
      "source": [
        "### Tokenize Target language sentences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zcyow_keWGHr"
      },
      "source": [
        "#Tokenizer for target language, filters should not <start> and <end>\n",
        "#remove < and > used in Target language sequences\n",
        "decoder_t = tf.keras.preprocessing.text.Tokenizer(filters='!\"#$%&()*+,-./:;=?@[\\\\]^_`{|}~\\t\\n')\n",
        "decoder_t.fit_on_texts(decoder_text) #Fit it on target sentences\n",
        "decoder_seq = decoder_t.texts_to_sequences(decoder_text) #Convert sentences to numbers "
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "phLrIK6WWGHt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78bf38cb-120a-4f99-e7db-a38bfe5a5078"
      },
      "source": [
        "#Maximum length of sentence\n",
        "max_decoder_seq_length = max([len(txt) for txt in decoder_seq])\n",
        "print('Maximum sentence length for Target language: ', max_decoder_seq_length)\n",
        "\n",
        "#Target language Vocablury\n",
        "decoder_vocab_size = len(decoder_t.word_index)\n",
        "print('Target language vocablury size: ', decoder_vocab_size)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Maximum sentence length for Target language:  27\n",
            "Target language vocablury size:  3059\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6fXf48uMWGH6"
      },
      "source": [
        "### Compare different sentences length"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w0aRkCfiWGH7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a04bbff-055f-4b08-a078-c2410a9b1d6a"
      },
      "source": [
        "#Source Language sentences\n",
        "print('Length for sentence number 100: ', len(encoder_seq[100]))\n",
        "print('Length for sentence number 2000: ', len(encoder_seq[2000]))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length for sentence number 100:  2\n",
            "Length for sentence number 2000:  8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W2qZN4BvWGH_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7fbdb9f2-8b1f-4973-b2dc-11edc5d6baeb"
      },
      "source": [
        "#Target Language sentences\n",
        "print('Length for sentence number 100: ', len(decoder_seq[100]))\n",
        "print('Length for sentence number 2000: ', len(decoder_seq[2000]))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length for sentence number 100:  5\n",
            "Length for sentence number 2000:  10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wmeSCSs6WGIC"
      },
      "source": [
        "### How do we make it same?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mqps8juMWGIE"
      },
      "source": [
        "### Padding the sentences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8rnbyRs9WGIF"
      },
      "source": [
        "#Source sentences\n",
        "encoder_input_data = tf.keras.preprocessing.sequence.pad_sequences(encoder_seq, \n",
        "                                                                   maxlen=max_encoder_seq_length, #22\n",
        "                                                                   padding='pre')\n",
        "\n",
        "#Target Sentences\n",
        "decoder_input_data = tf.keras.preprocessing.sequence.pad_sequences(decoder_seq, \n",
        "                                                                   maxlen=max_decoder_seq_length, #27\n",
        "                                                                   padding='post')"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a61g_ADpWGIH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a949bcc-c420-493e-8240-4d0921b1473b"
      },
      "source": [
        "print('Source data shape: ', encoder_input_data.shape)\n",
        "print('Target data shape: ', decoder_input_data.shape)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Source data shape:  (2949, 22)\n",
            "Target data shape:  (2949, 27)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nl4oxg8cWGIJ"
      },
      "source": [
        "#### Integer to Word converter for Decoder data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jhwnBD-0WGIK"
      },
      "source": [
        "int_to_word_decoder = dict((i,c) for c, i in decoder_t.word_index.items())"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q8TP07uxWGIP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ad9b5d31-5e2d-4f2f-e3d8-fc3ace55d056"
      },
      "source": [
        "int_to_word_decoder[15]"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'हैं।'"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5g4Y4oRvWGIV"
      },
      "source": [
        "### Building Decoder Output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YuoPA9aWWGIV"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "#Initialize array\n",
        "decoder_target_data = np.zeros((decoder_input_data.shape[0], decoder_input_data.shape[1]))\n",
        "\n",
        "#Shift Target output by one word\n",
        "for i in range(decoder_input_data.shape[0]):\n",
        "    for j in range(1,decoder_input_data.shape[1]):\n",
        "        decoder_target_data[i][j-1] = decoder_input_data[i][j]"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "haordQCuWGIX"
      },
      "source": [
        "#### Convert target data in one hot vector"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vs2SKKI5WGIY"
      },
      "source": [
        "#Initialize one hot encoding array\n",
        "decoder_target_one_hot = np.zeros((decoder_input_data.shape[0], #number of sentences\n",
        "                                   decoder_input_data.shape[1], #Number of words in each sentence\n",
        "                                   len(decoder_t.word_index)+1)) #Vocab size + 1"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xoX_6OP4WGIm"
      },
      "source": [
        "#Build one hot encoded array\n",
        "for i in range(decoder_target_data.shape[0]):\n",
        "    for j in range(decoder_target_data.shape[1]):\n",
        "        decoder_target_one_hot[i][j] = tf.keras.utils.to_categorical(decoder_target_data[i][j],\n",
        "                                                                     num_classes=len(decoder_t.word_index)+1)    "
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y5fO1TTWWGIo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8950b556-bcaa-4da3-c8c7-cbd9d30efdab"
      },
      "source": [
        "decoder_target_one_hot.shape"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2949, 27, 3060)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fQYFym0AWGIq"
      },
      "source": [
        "### Building the Training Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XnDjHynRi24U"
      },
      "source": [
        "tf.keras.backend.clear_session()"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fRfYeB2AWGIr"
      },
      "source": [
        "#Define config parameters\n",
        "encoder_embedding_size = 50\n",
        "decoder_embedding_size = 50\n",
        "rnn_units = 256"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "71ukvjyeWGIt"
      },
      "source": [
        "#### Build Encoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2SHW_YvkWGIw"
      },
      "source": [
        "#Input Layer\n",
        "encoder_inputs = tf.keras.layers.Input(shape=(22,))\n",
        "\n",
        "#Embedding layer\n",
        "encoder_embedding = tf.keras.layers.Embedding(encoder_vocab_size+1, encoder_embedding_size)\n",
        "\n",
        "#Get embedding layer output by feeding inputs\n",
        "encoder_embedding_output = encoder_embedding(encoder_inputs)\n",
        "\n",
        "#---Following code has been commented out for Attention-------\n",
        "#LSTM Layer and its output\n",
        "#x, state_h, state_c = tf.keras.layers.LSTM(rnn_units,return_state=True)(encoder_embedding_output)\n",
        "\n",
        "#Build a list to feed Decoder\n",
        "#encoder_states = [state_h, state_c]"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YbfLAFglWGIx"
      },
      "source": [
        "#### Build Encoder - Get all hidden states"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EnZJnNSbWGIz"
      },
      "source": [
        "#Create LSTM Layer and get All hidden states, last hidden and cell state\n",
        "encoder_lstm = tf.keras.layers.LSTM(rnn_units,return_state=True, return_sequences=True)\n",
        "\n",
        "#Get 3 outputs of LSTM Layer\n",
        "encoder_all_h_states, state_h, state_c = encoder_lstm(encoder_embedding_output)\n",
        "\n",
        "#Build a list to feed Decoder\n",
        "encoder_states = [state_h, state_c]"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1OcK7SYUjDdf",
        "outputId": "3f38458b-7833-41ea-8877-0002172ca55c"
      },
      "source": [
        "encoder_all_h_states"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<KerasTensor: shape=(None, 22, 256) dtype=float32 (created by layer 'lstm')>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RAIuXWK5WGI1"
      },
      "source": [
        "#### Build Decoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uYY-zwUSWGI2"
      },
      "source": [
        "#Decode input - padded Target sentences\n",
        "decoder_inputs = tf.keras.layers.Input(shape=(27,))\n",
        "\n",
        "#Decoder Embedding layer\n",
        "decoder_embedding = tf.keras.layers.Embedding(decoder_vocab_size + 1, decoder_embedding_size)\n",
        "\n",
        "#Embedding layer output\n",
        "decoder_embedding_output = decoder_embedding(decoder_inputs)\n",
        "\n",
        "#Decoder RNN\n",
        "decoder_rnn = tf.keras.layers.LSTM(rnn_units, return_sequences=True, return_state=True)\n",
        "\n",
        "#Decoder RNN Output, State initialization from Encoder states\n",
        "#Output will be all hidden sequences, last 'h' state and last 'c' state\n",
        "decoder_all_h_states,_,_ = decoder_rnn(decoder_embedding_output, \n",
        "                                       initial_state=encoder_states)\n",
        "\n",
        "#---Following code has been commented out for Attention-------\n",
        "#Output Layer\n",
        "#decoder_dense = tf.keras.layers.Dense(decoder_vocab_size + 1, activation='softmax')\n",
        "\n",
        "#Output of Dense layer\n",
        "#decoder_outputs = decoder_dense(x)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tLmAljrtjAGq",
        "outputId": "3f7ab4ef-2a54-4e09-f436-b77e8184c9bb"
      },
      "source": [
        "decoder_all_h_states"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<KerasTensor: shape=(None, 27, 256) dtype=float32 (created by layer 'lstm_1')>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QwtwXesXWGI4"
      },
      "source": [
        "#### Build Decoder...Alignment Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mOJtf8kMWGI5"
      },
      "source": [
        "#1. Dot Product between Decoder_all_h_states and encoder_all_h_states\n",
        "#2. Apply softmax to get Alignment matrix\n",
        "\n",
        "#Dimensions details\n",
        "#decoder_all_states = batch_size x max_decoder_length x rnn_units\n",
        "#encoder_all_states = batch_size x max_encoder_length x rnn_units\n",
        "#score = batch_size x max_decoder_length x max_encoder_length\n",
        "#alignment matrix = batch_size x max_decoder_length x max_encoder_length\n",
        "\n",
        "score = tf.keras.layers.dot([decoder_all_h_states, encoder_all_h_states], axes=2)\n",
        "alignment_matrix = tf.keras.layers.Activation('softmax')(score)\n",
        "\n",
        "#Try general and concat approaches to alignment matrix"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SNzzFkm4W0N8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a232d948-2065-4c94-a0e0-9bb8cf879f63"
      },
      "source": [
        "alignment_matrix"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<KerasTensor: shape=(None, 27, 22) dtype=float32 (created by layer 'activation')>"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cYFfIGyvWGI6"
      },
      "source": [
        "#### Build Decoder...Context Vector"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h4ICneq6WGI6"
      },
      "source": [
        "#Weighted sum of multiplication of Alignment matrix and encoder states\n",
        "#Dimension of context_vector =  batch_size x max_decoder_length x rnn_units\n",
        "\n",
        "context_vector = tf.keras.layers.dot([alignment_matrix, encoder_all_h_states], axes=[2,1])"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S3EtN7Ho9fHy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d4f3fa9-3cb8-4be5-a3b9-20514ea02010"
      },
      "source": [
        "context_vector"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<KerasTensor: shape=(None, 27, 256) dtype=float32 (created by layer 'dot_1')>"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4GOKQuJiWGI8"
      },
      "source": [
        "#### Build Decoder...Attention Vector"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L9aJaK5LWGI8"
      },
      "source": [
        "#Concatenate context vector and decoder_all_h_states\n",
        "#context_decoder_hidden = batch_size x max_decoder_length x rnn_units\n",
        "#attention_vector = batch_size x max_decoder_length x 128\n",
        "\n",
        "context_decoder_hidden = tf.keras.layers.concatenate([context_vector, \n",
        "                                                      decoder_all_h_states])\n",
        "\n",
        "attention_dense_layer = tf.keras.layers.Dense(128, use_bias=False, \n",
        "                                              activation='relu')\n",
        "\n",
        "attention_vector = attention_dense_layer(context_decoder_hidden)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v1nE-nHNfqix",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4de1a57e-1ed0-427e-97a3-79fc792d00f9"
      },
      "source": [
        "attention_vector"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<KerasTensor: shape=(None, 27, 128) dtype=float32 (created by layer 'dense')>"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yvcsEikBWGI-"
      },
      "source": [
        "#### Build Decoder...Output layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GinU4PH5WGI_"
      },
      "source": [
        "#Output layer\n",
        "decoder_dense = tf.keras.layers.Dense(decoder_vocab_size + 1, activation='softmax')\n",
        "\n",
        "#With attention input will be attention_vector and not decoder_all_h_states\n",
        "decoder_outputs = decoder_dense(attention_vector)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K2CHFVvmkB06",
        "outputId": "cdf4e1f0-795e-4673-a1b8-b78e9e27d3c0"
      },
      "source": [
        "decoder_outputs"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<KerasTensor: shape=(None, 27, 3060) dtype=float32 (created by layer 'dense_1')>"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "__FmqX3qWGJL"
      },
      "source": [
        "### Build Model using both Encoder and Decoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IbtWE0_JWGJL"
      },
      "source": [
        "model = tf.keras.models.Model([encoder_inputs, decoder_inputs], #2 Inputs to the model\n",
        "                              decoder_outputs) #Output of the model"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WG4pyK_jWGJO"
      },
      "source": [
        "model.compile(optimizer='adam', \n",
        "              loss='categorical_crossentropy', \n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xA0TU2tCVYLO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8c0d87a-cf47-4dde-fbb1-0d92e79f8d17"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 22)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 27)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 22, 50)       121650      input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, 27, 50)       153000      input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     [(None, 22, 256), (N 314368      embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   [(None, 27, 256), (N 314368      embedding_1[0][0]                \n",
            "                                                                 lstm[0][1]                       \n",
            "                                                                 lstm[0][2]                       \n",
            "__________________________________________________________________________________________________\n",
            "dot (Dot)                       (None, 27, 22)       0           lstm_1[0][0]                     \n",
            "                                                                 lstm[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 27, 22)       0           dot[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "dot_1 (Dot)                     (None, 27, 256)      0           activation[0][0]                 \n",
            "                                                                 lstm[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 27, 512)      0           dot_1[0][0]                      \n",
            "                                                                 lstm_1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 27, 128)      65536       concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 27, 3060)     394740      dense[0][0]                      \n",
            "==================================================================================================\n",
            "Total params: 1,363,662\n",
            "Trainable params: 1,363,662\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uHhrDTBZWGJQ"
      },
      "source": [
        "### Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "81ciKSvCWGJQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95bd2f85-fae2-4dad-a700-6c128d123149"
      },
      "source": [
        "model.fit([encoder_input_data, decoder_input_data], decoder_target_one_hot,\n",
        "          batch_size=64,\n",
        "          epochs=25,\n",
        "          validation_split=0.2)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "37/37 [==============================] - 22s 491ms/step - loss: 3.4973 - accuracy: 0.7179 - val_loss: 3.1014 - val_accuracy: 0.5922\n",
            "Epoch 2/25\n",
            "37/37 [==============================] - 17s 458ms/step - loss: 1.6445 - accuracy: 0.7435 - val_loss: 3.0277 - val_accuracy: 0.5952\n",
            "Epoch 3/25\n",
            "37/37 [==============================] - 17s 452ms/step - loss: 1.5739 - accuracy: 0.7464 - val_loss: 2.9319 - val_accuracy: 0.5956\n",
            "Epoch 4/25\n",
            "37/37 [==============================] - 17s 452ms/step - loss: 1.4899 - accuracy: 0.7561 - val_loss: 2.7617 - val_accuracy: 0.6097\n",
            "Epoch 5/25\n",
            "37/37 [==============================] - 17s 456ms/step - loss: 1.4143 - accuracy: 0.7753 - val_loss: 2.7916 - val_accuracy: 0.6234\n",
            "Epoch 6/25\n",
            "37/37 [==============================] - 17s 456ms/step - loss: 1.3736 - accuracy: 0.7803 - val_loss: 2.7674 - val_accuracy: 0.6307\n",
            "Epoch 7/25\n",
            "37/37 [==============================] - 17s 456ms/step - loss: 1.3439 - accuracy: 0.7831 - val_loss: 2.7196 - val_accuracy: 0.6357\n",
            "Epoch 8/25\n",
            "37/37 [==============================] - 17s 459ms/step - loss: 1.3202 - accuracy: 0.7859 - val_loss: 2.8144 - val_accuracy: 0.6334\n",
            "Epoch 9/25\n",
            "37/37 [==============================] - 17s 461ms/step - loss: 1.3005 - accuracy: 0.7884 - val_loss: 2.8471 - val_accuracy: 0.6329\n",
            "Epoch 10/25\n",
            "37/37 [==============================] - 17s 463ms/step - loss: 1.2831 - accuracy: 0.7893 - val_loss: 2.7849 - val_accuracy: 0.6388\n",
            "Epoch 11/25\n",
            "37/37 [==============================] - 17s 458ms/step - loss: 1.2678 - accuracy: 0.7894 - val_loss: 2.7858 - val_accuracy: 0.6401\n",
            "Epoch 12/25\n",
            "37/37 [==============================] - 17s 461ms/step - loss: 1.2539 - accuracy: 0.7911 - val_loss: 2.8553 - val_accuracy: 0.6389\n",
            "Epoch 13/25\n",
            "37/37 [==============================] - 17s 458ms/step - loss: 1.2384 - accuracy: 0.7919 - val_loss: 2.9266 - val_accuracy: 0.6397\n",
            "Epoch 14/25\n",
            "37/37 [==============================] - 17s 461ms/step - loss: 1.2264 - accuracy: 0.7933 - val_loss: 2.8728 - val_accuracy: 0.6410\n",
            "Epoch 15/25\n",
            "37/37 [==============================] - 17s 456ms/step - loss: 1.2157 - accuracy: 0.7935 - val_loss: 2.9183 - val_accuracy: 0.6416\n",
            "Epoch 16/25\n",
            "37/37 [==============================] - 17s 457ms/step - loss: 1.2022 - accuracy: 0.7944 - val_loss: 2.9547 - val_accuracy: 0.6417\n",
            "Epoch 17/25\n",
            "37/37 [==============================] - 17s 455ms/step - loss: 1.1908 - accuracy: 0.7950 - val_loss: 2.9651 - val_accuracy: 0.6436\n",
            "Epoch 18/25\n",
            "37/37 [==============================] - 17s 450ms/step - loss: 1.1798 - accuracy: 0.7967 - val_loss: 2.9731 - val_accuracy: 0.6435\n",
            "Epoch 19/25\n",
            "37/37 [==============================] - 17s 459ms/step - loss: 1.1687 - accuracy: 0.7964 - val_loss: 2.9974 - val_accuracy: 0.6434\n",
            "Epoch 20/25\n",
            "37/37 [==============================] - 17s 459ms/step - loss: 1.1548 - accuracy: 0.7975 - val_loss: 3.0051 - val_accuracy: 0.6451\n",
            "Epoch 21/25\n",
            "37/37 [==============================] - 17s 460ms/step - loss: 1.1395 - accuracy: 0.7987 - val_loss: 2.9840 - val_accuracy: 0.6465\n",
            "Epoch 22/25\n",
            "37/37 [==============================] - 17s 455ms/step - loss: 1.1263 - accuracy: 0.7992 - val_loss: 3.0964 - val_accuracy: 0.6446\n",
            "Epoch 23/25\n",
            "37/37 [==============================] - 17s 456ms/step - loss: 1.1102 - accuracy: 0.8004 - val_loss: 3.0177 - val_accuracy: 0.6471\n",
            "Epoch 24/25\n",
            "37/37 [==============================] - 17s 455ms/step - loss: 1.0915 - accuracy: 0.8019 - val_loss: 3.0696 - val_accuracy: 0.6472\n",
            "Epoch 25/25\n",
            "37/37 [==============================] - 17s 456ms/step - loss: 1.0747 - accuracy: 0.8041 - val_loss: 3.1750 - val_accuracy: 0.6466\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fca143100d0>"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0gO-p-OaWGJT"
      },
      "source": [
        "### Save the model for later reuse"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GUJcwtNyWGJU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2f832ef-2bbc-439d-8f5f-f18967bc6ee5"
      },
      "source": [
        "#model.save('models/seq2seq_training_translation_attention.hd5')\n",
        "# Mounting the drive \n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z8k64d1HWGJY"
      },
      "source": [
        "# Building Model for Prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_w__FLXCWGJZ"
      },
      "source": [
        "### Build the Encoder Model to predict Encoder States"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x9sSoCtMWGJZ"
      },
      "source": [
        "encoder_model = tf.keras.models.Model(inputs=encoder_inputs, #Padded input sequences\n",
        "                                      outputs=[encoder_all_h_states] + #Hidden states at all time steps\n",
        "                                      encoder_states) #Hidden state and Cell state at last time step"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RScHHgr5WGJb"
      },
      "source": [
        "### Build the Decoder Model \n",
        "<p/>\n",
        "\n",
        "<ol><li>Define Input for both 'h' state and 'c' state initialization </li>\n",
        "    <li><font color=\"blue\">Define Input for all encoder states - Attention Layer </font></li>\n",
        "<li>Get Decoder RNN outputs along with h and c state</li>\n",
        "<li><font color=\"blue\">Build Attention Layer</font></li>\n",
        "<li><font color=\"blue\">Get Decoder Dense layer output using Attention vector</font></li>\n",
        "    <li><font color=\"blue\">Build Model</font></li></ol>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fZGRM_UQWGJc"
      },
      "source": [
        "##### Step 1 - Define Input for both 'h' state and 'c' state initialization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wq4XvgTAWGJc"
      },
      "source": [
        "#Hidden state input\n",
        "decoder_state_input_h = tf.keras.layers.Input(shape=(rnn_units,))\n",
        "\n",
        "#Cell state input\n",
        "decoder_state_input_c = tf.keras.layers.Input(shape=(rnn_units,))\n",
        "\n",
        "#Putting it together\n",
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U4rg9wJMWGJe"
      },
      "source": [
        "##### Step 2 - Define Input encoder states - Attention Layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SYozwBH2WGJe"
      },
      "source": [
        "encoder_outputs = tf.keras.layers.Input(shape=(max_encoder_seq_length, rnn_units,))"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cu7AJ7teWGJg"
      },
      "source": [
        "##### Step 3 - Get Decoder RNN outputs along with h and c state"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TPbxVkdoWGJh"
      },
      "source": [
        "#Get Embedding layer output\n",
        "x = decoder_embedding(decoder_inputs)\n",
        "\n",
        "#We will use the layer which we trained earlier\n",
        "rnn_outputs, state_h, state_c = decoder_rnn(x, initial_state=decoder_states_inputs)\n",
        "\n",
        "#Why do we need this?\n",
        "decoder_states = [state_h, state_c]"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YnDK-mtkWGJk"
      },
      "source": [
        "##### Step 4 - Build Attention Layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9RFkceyHWGJk"
      },
      "source": [
        "#Alignment score\n",
        "p_score = tf.keras.layers.dot([rnn_outputs, encoder_outputs], axes=2)\n",
        "\n",
        "#Perform softmax to get Alignment matrix\n",
        "p_alignment_matrix = tf.keras.layers.Activation('softmax')(p_score)\n",
        "\n",
        "#Context Vector\n",
        "p_context_vector = tf.keras.layers.dot([p_alignment_matrix, encoder_outputs], axes=[2,1])\n",
        "\n",
        "#Build Attention Vector\n",
        "# 1. Caoncatenate both context vector and decoder outputs\n",
        "# 2. Feed it to the Dense layer \n",
        "p_context_decoder_hidden = tf.keras.layers.concatenate([p_context_vector, rnn_outputs])\n",
        "p_attention_vector = attention_dense_layer(p_context_decoder_hidden)"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CLw9G3KkWGJl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "295c78f8-d7f2-46b5-fd22-5b442fe822b5"
      },
      "source": [
        "p_alignment_matrix"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<KerasTensor: shape=(None, 27, 22) dtype=float32 (created by layer 'activation_1')>"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fUVTE025WGJn"
      },
      "source": [
        "##### Step 5 - Get Decoder Dense layer output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o60fmWbJWGJo"
      },
      "source": [
        "decoder_outputs = decoder_dense(p_attention_vector)"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oE7o-lOfWGJ3"
      },
      "source": [
        "##### Step 6 - Build Decoder Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "545vI4cXWGJ4"
      },
      "source": [
        "#3 Inputs - Word, h/c state and all hidden states from encoder\n",
        "#3 Outputs - predicted word, h and c state values for next run and alignment matrix for visualization\n",
        "\n",
        "decoder_model = tf.keras.models.Model([decoder_inputs] +  #Start sequence and then word\n",
        "                                      decoder_states_inputs + #h and c state value for initialization\n",
        "                                      [encoder_outputs],  #Encoder all hidden states for Attention layer\n",
        "                                      [decoder_outputs] + #Model word prediction\n",
        "                                      decoder_states +   #h and c states for next run\n",
        "                                      [p_alignment_matrix]) #for Alignment matrix"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G7VEzNGyWGJ5"
      },
      "source": [
        "# Predicting output from Seq2Seq model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mcg5mBcYWGJ6"
      },
      "source": [
        "##### Build a prediction function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1VoPsIkWGJ6"
      },
      "source": [
        "def decode_sentence(input_sequence):\n",
        "    \n",
        "    #Get the encoder state values\n",
        "    encoder_output =  encoder_model.predict(input_sequence)\n",
        "    decoder_initial_states_value = encoder_output[1:]    \n",
        "    encoded_seqs = encoder_output[0]\n",
        "    \n",
        "    #Build a sequence with '<start>' - starting sequence for Decoder\n",
        "    target_seq = np.zeros((1,1))    \n",
        "    target_seq[0][0] = decoder_t.word_index['<start>']\n",
        "    \n",
        "    #flag to check if prediction should be stopped\n",
        "    stop_loop = False\n",
        "    \n",
        "    #Initialize predicted sentence\n",
        "    predicted_sentence = ''\n",
        "    \n",
        "    #start the loop\n",
        "    while not stop_loop:\n",
        "        \n",
        "        #Decoder model with 3 inputs\n",
        "        predicted_outputs, h, c, a_matrix = decoder_model.predict([target_seq] + \n",
        "                                                                  decoder_initial_states_value +\n",
        "                                                                  [encoded_seqs])\n",
        "        \n",
        "        #Get the predicted word index with highest probability\n",
        "        predicted_output = np.argmax(predicted_outputs[0,-1,:])\n",
        "        \n",
        "        #Get the predicted word from predicter index\n",
        "        if (predicted_output == 0):\n",
        "            predicted_word = ' '\n",
        "        else:\n",
        "            predicted_word = int_to_word_decoder[predicted_output]\n",
        "        \n",
        "        #Check if prediction should stop\n",
        "        if(predicted_word == '<end>' or len(predicted_sentence) > max_decoder_seq_length):\n",
        "            \n",
        "            stop_loop = True\n",
        "            continue\n",
        "                    \n",
        "        #Updated predicted sentence\n",
        "        if (len(predicted_sentence) == 0):\n",
        "            predicted_sentence = predicted_word\n",
        "        else:\n",
        "            predicted_sentence = predicted_sentence + ' ' + predicted_word\n",
        "            \n",
        "        #Update target_seq to be the predicted word index\n",
        "        target_seq[0][0] = predicted_output\n",
        "        \n",
        "        #Update initial states value for decoder\n",
        "        decoder_initial_states_value = [h,c]\n",
        "        \n",
        "        print(a_matrix[0][0])\n",
        "    \n",
        "    return predicted_sentence"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CuQcVTVZWGJ8"
      },
      "source": [
        "##### Call Prediction function on a random sentence"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jkJznTF8WGJ9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7352107-3968-46ca-c931-4a2d9b630a99"
      },
      "source": [
        "#Generate a random number\n",
        "start_num = np.random.randint(0, high=len(encoder_text) - 10)\n",
        "\n",
        "#Predict model output for 5 sentences\n",
        "for i in range(start_num, start_num + 1):\n",
        "    input_seq = encoder_input_data[i : i+1]\n",
        "    #print(input_seq)\n",
        "    predicted_sentence = decode_sentence(input_seq)\n",
        "    print('--------')\n",
        "    print ('Input sentence: ', encoder_text[i])\n",
        "    print ('Predicted sentence: ', predicted_sentence )"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 27) for input KerasTensor(type_spec=TensorSpec(shape=(None, 27), dtype=tf.float32, name='input_2'), name='input_2', description=\"created by layer 'input_2'\"), but it was called on an input with incompatible shape (None, 1).\n",
            "[3.7672151e-34 2.2714981e-32 3.2633345e-29 1.0993100e-23 2.2040253e-15\n",
            " 1.1646388e-07 2.8266851e-04 1.8437083e-03 2.8128640e-03 3.2110440e-03\n",
            " 3.3790634e-03 3.4470507e-03 5.6149145e-03 1.4614068e-02 9.7474694e-05\n",
            " 5.4093588e-02 5.7433151e-02 7.1678221e-02 1.0486840e-02 2.1216350e-02\n",
            " 3.6777902e-02 7.1301097e-01]\n",
            "[2.3213180e-19 2.4091077e-18 1.5186012e-16 2.1100379e-13 1.0176914e-08\n",
            " 1.7892788e-04 9.9062920e-03 2.3624495e-02 2.8417118e-02 3.0205358e-02\n",
            " 3.1008119e-02 3.1385247e-02 1.7009465e-02 2.4335396e-02 2.9669602e-05\n",
            " 1.3379433e-02 2.2974728e-02 1.0423099e-01 6.5595128e-02 1.7308801e-01\n",
            " 1.3043706e-01 2.9419461e-01]\n",
            "[8.0844308e-16 5.5503185e-15 1.7036070e-13 6.7515285e-11 4.7376801e-07\n",
            " 1.1891886e-03 2.4095334e-02 4.2101432e-02 4.6410084e-02 4.7968678e-02\n",
            " 4.8743594e-02 4.9151391e-02 1.3799993e-02 1.7232647e-02 7.3605183e-06\n",
            " 3.5640816e-03 9.0026353e-03 7.5863354e-02 8.8264592e-02 2.5852606e-01\n",
            " 1.5063880e-01 1.2344031e-01]\n",
            "[2.29217578e-13 1.04277687e-12 1.52178530e-11 1.61932523e-09\n",
            " 1.67892756e-06 9.59273137e-04 1.40532209e-02 2.56490763e-02\n",
            " 2.89549883e-02 2.99559403e-02 3.03059854e-02 3.04157231e-02\n",
            " 3.80943120e-02 5.70067540e-02 2.22394546e-03 4.23273966e-02\n",
            " 5.68908565e-02 7.99568892e-02 4.45053428e-02 8.22139829e-02\n",
            " 1.12657756e-01 3.23826969e-01]\n",
            "[6.8580355e-14 3.6385275e-13 7.0289156e-12 1.2243087e-09 2.5260895e-06\n",
            " 2.2932838e-03 3.3777423e-02 5.5180240e-02 5.8211960e-02 5.8213066e-02\n",
            " 5.7808988e-02 5.7380997e-02 2.9046681e-02 5.2825667e-02 5.9844996e-04\n",
            " 1.8488355e-02 3.9600760e-02 7.5328566e-02 5.3851638e-02 1.2181130e-01\n",
            " 1.5557513e-01 1.3000500e-01]\n",
            "[1.2674693e-11 5.2344403e-11 6.4985589e-10 5.1871297e-08 3.1683641e-05\n",
            " 8.3326548e-03 6.4016059e-02 8.3682723e-02 8.1596382e-02 7.8793526e-02\n",
            " 7.6817952e-02 7.5444169e-02 2.5785079e-02 5.1309004e-02 8.0966408e-04\n",
            " 1.6267128e-02 3.8305286e-02 6.2718034e-02 4.8786383e-02 1.0220863e-01\n",
            " 1.3090947e-01 5.4186080e-02]\n",
            "[1.1268445e-11 4.7092219e-11 6.0408728e-10 5.1732506e-08 3.5407716e-05\n",
            " 1.0399793e-02 8.2812957e-02 1.0503379e-01 9.8662779e-02 9.2862941e-02\n",
            " 8.9058936e-02 8.6538628e-02 2.1688677e-02 5.6786120e-02 2.0642842e-03\n",
            " 2.0528553e-02 5.2064668e-02 5.2192632e-02 3.5256609e-02 6.6383876e-02\n",
            " 1.0414488e-01 2.3484444e-02]\n",
            "--------\n",
            "Input sentence:  The doctor told her that she should take a rest.\n",
            "Predicted sentence:  मुझे अपने पास एक एक बहुत नहीं\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YS-RjZPlWGJ-"
      },
      "source": [
        "##### Save encoder and decoder model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2l-qAT-bWGJ-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "313550bf-60e8-43cc-a4dc-0419c6b29095"
      },
      "source": [
        "#Compile models to avoid error\n",
        "encoder_model.compile(optimizer='adam',loss='categorical_crossentropy')\n",
        "decoder_model.compile(optimizer='adam',loss='categorical_crossentropy')\n",
        "\n",
        "#Save the models\n",
        "encoder_model.save('models/seq2seq_encoder_eng_hin.hd5')  #Encoder model\n",
        "decoder_model.save('models/seq2seq_decoder_eng_hin.hd5')  #Decoder model"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: models/seq2seq_encoder_eng_hin.hd5/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: models/seq2seq_encoder_eng_hin.hd5/assets\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: models/seq2seq_decoder_eng_hin.hd5/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: models/seq2seq_decoder_eng_hin.hd5/assets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oh0okCv0WGKA"
      },
      "source": [
        "##### Save encoder and decoder tokenizers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qwfb-v7OWGKB"
      },
      "source": [
        "import pickle\n",
        "\n",
        "pickle.dump(encoder_t,open('models/encoder_tokenizer_eng','wb'))\n",
        "pickle.dump(decoder_t,open('models/decoder_tokenizer_hin','wb'))"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8JadcytNtlWa"
      },
      "source": [
        ""
      ],
      "execution_count": 59,
      "outputs": []
    }
  ]
}