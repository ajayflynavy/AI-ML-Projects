{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    },
    "colab": {
      "name": "4c. Sentiment_Analysis_Glove_Embedding.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "mQKm7K78KMQa",
        "40sSeDoWKMQx",
        "2GgPOuSzKMRA",
        "fKmVWM5pKMRF",
        "wAOvV9C_KMRl",
        "j_aH5TX5KMSA",
        "2NvjDJo7OYOb"
      ]
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mQKm7K78KMQa"
      },
      "source": [
        "#### Load Movie reviews Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IS0axMJDKrph"
      },
      "source": [
        "We will be using data available on Kaggle platform for this exercise. The data is available at https://www.kaggle.com/c/word2vec-nlp-tutorial/data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WxnI1KLhLJ_J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14ae1255-9b42-4a81-d9bc-b4f12d8148a6"
      },
      "source": [
        "#Connect Google drive to colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zDssadQzJnmz"
      },
      "source": [
        "Load dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Y_ohNjGKt6R"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pb3r_KaeJJ0d"
      },
      "source": [
        "#change file path to point to where you have stored the zip file.\n",
        "df = pd.read_csv('/content/drive/MyDrive/AIML/NLP/Rajeev Sir/Statistical NLP- Rajeev.zip (Unzipped Files)/Notebooks.zip (Unzipped Files)/Notebooks/data/labeledTrainData.tsv.zip (Unzipped Files)/labeledTrainData.tsv', header=0, delimiter=\"\\t\", quoting=3)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l70lgDrNJZ-F",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 220
        },
        "outputId": "590fece0-b1c4-4a4d-d40b-14acdcd7ad9f"
      },
      "source": [
        "print('Number of examples in Dataset: ', df.shape)\n",
        "df.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of examples in Dataset:  (25000, 3)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>\"5814_8\"</td>\n",
              "      <td>1</td>\n",
              "      <td>\"With all this stuff going down at the moment ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>\"2381_9\"</td>\n",
              "      <td>1</td>\n",
              "      <td>\"\\\"The Classic War of the Worlds\\\" by Timothy ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>\"7759_3\"</td>\n",
              "      <td>0</td>\n",
              "      <td>\"The film starts with a manager (Nicholas Bell...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>\"3630_4\"</td>\n",
              "      <td>0</td>\n",
              "      <td>\"It must be assumed that those who praised thi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>\"9495_8\"</td>\n",
              "      <td>1</td>\n",
              "      <td>\"Superbly trashy and wondrously unpretentious ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         id  sentiment                                             review\n",
              "0  \"5814_8\"          1  \"With all this stuff going down at the moment ...\n",
              "1  \"2381_9\"          1  \"\\\"The Classic War of the Worlds\\\" by Timothy ...\n",
              "2  \"7759_3\"          0  \"The film starts with a manager (Nicholas Bell...\n",
              "3  \"3630_4\"          0  \"It must be assumed that those who praised thi...\n",
              "4  \"9495_8\"          1  \"Superbly trashy and wondrously unpretentious ..."
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q12_oUDIIC-k",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        },
        "outputId": "6dad5252-6ce9-4828-ba0a-c756ba61db62"
      },
      "source": [
        "df.loc[0, 'review']"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\"With all this stuff going down at the moment with MJ i\\'ve started listening to his music, watching the odd documentary here and there, watched The Wiz and watched Moonwalker again. Maybe i just want to get a certain insight into this guy who i thought was really cool in the eighties just to maybe make up my mind whether he is guilty or innocent. Moonwalker is part biography, part feature film which i remember going to see at the cinema when it was originally released. Some of it has subtle messages about MJ\\'s feeling towards the press and also the obvious message of drugs are bad m\\'kay.<br /><br />Visually impressive but of course this is all about Michael Jackson so unless you remotely like MJ in anyway then you are going to hate this and find it boring. Some may call MJ an egotist for consenting to the making of this movie BUT MJ and most of his fans would say that he made it for the fans which if true is really nice of him.<br /><br />The actual feature film bit when it finally starts is only on for 20 minutes or so excluding the Smooth Criminal sequence and Joe Pesci is convincing as a psychopathic all powerful drug lord. Why he wants MJ dead so bad is beyond me. Because MJ overheard his plans? Nah, Joe Pesci\\'s character ranted that he wanted people to know it is he who is supplying drugs etc so i dunno, maybe he just hates MJ\\'s music.<br /><br />Lots of cool things in this like MJ turning into a car and a robot and the whole Speed Demon sequence. Also, the director must have had the patience of a saint when it came to filming the kiddy Bad sequence as usually directors hate working with one kid let alone a whole bunch of them performing a complex dance scene.<br /><br />Bottom line, this movie is for people who like MJ on one level or another (which i think is most people). If not, then stay away. It does try and give off a wholesome message and ironically MJ\\'s bestest buddy in this movie is a girl! Michael Jackson is truly one of the most talented people ever to grace this planet but is he guilty? Well, with all the attention i\\'ve gave this subject....hmmm well i don\\'t know because people can be different behind closed doors, i know this for a fact. He is either an extremely nice but stupid guy or one of the most sickest liars. I hope he is not the latter.\"'"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45uxRF4rKMQq"
      },
      "source": [
        "Split Data into Training and Test Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cwNZ5XEpKMQq"
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q-RNaPq2KMQt"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    df['review'],\n",
        "    df['sentiment'],\n",
        "    test_size=0.2, \n",
        "    random_state=42\n",
        ")"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IdMWitcdByBs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63f04d31-d46a-4cec-a97c-f259b425d2e6"
      },
      "source": [
        "X_train.shape, X_test.shape"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((20000,), (5000,))"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "40sSeDoWKMQx"
      },
      "source": [
        "#### Build the Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AGM55RRUM3fN"
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LNB6T0EVKMQ6"
      },
      "source": [
        "desired_vocab_size = 10000 #Vocablury size\n",
        "t = tf.keras.preprocessing.text.Tokenizer(num_words=desired_vocab_size, oov_token=32) # num_words -> Vocablury size"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t65mfe_2KMQ8"
      },
      "source": [
        "#Fit tokenizer with actual training data\n",
        "t.fit_on_texts(X_train.tolist())"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6N7cgYEvVGzB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7d34a0d-f725-4bf9-86e3-52083d66010b"
      },
      "source": [
        "#Vocabulary\n",
        "t.word_index"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{32: 1,\n",
              " 'the': 2,\n",
              " 'and': 3,\n",
              " 'a': 4,\n",
              " 'of': 5,\n",
              " 'to': 6,\n",
              " 'is': 7,\n",
              " 'br': 8,\n",
              " 'in': 9,\n",
              " 'it': 10,\n",
              " 'i': 11,\n",
              " 'this': 12,\n",
              " 'that': 13,\n",
              " 'was': 14,\n",
              " 'as': 15,\n",
              " 'for': 16,\n",
              " 'with': 17,\n",
              " 'movie': 18,\n",
              " 'but': 19,\n",
              " 'film': 20,\n",
              " 'on': 21,\n",
              " 'not': 22,\n",
              " 'you': 23,\n",
              " 'his': 24,\n",
              " 'are': 25,\n",
              " 'have': 26,\n",
              " 'he': 27,\n",
              " 'be': 28,\n",
              " 'one': 29,\n",
              " 'all': 30,\n",
              " 'at': 31,\n",
              " 'by': 32,\n",
              " 'an': 33,\n",
              " 'they': 34,\n",
              " 'who': 35,\n",
              " 'so': 36,\n",
              " 'from': 37,\n",
              " 'like': 38,\n",
              " 'her': 39,\n",
              " 'or': 40,\n",
              " 'just': 41,\n",
              " 'about': 42,\n",
              " \"it's\": 43,\n",
              " 'out': 44,\n",
              " 'has': 45,\n",
              " 'if': 46,\n",
              " 'there': 47,\n",
              " 'some': 48,\n",
              " 'what': 49,\n",
              " 'good': 50,\n",
              " 'more': 51,\n",
              " 'when': 52,\n",
              " 'very': 53,\n",
              " 'up': 54,\n",
              " 'no': 55,\n",
              " 'even': 56,\n",
              " 'time': 57,\n",
              " 'she': 58,\n",
              " 'my': 59,\n",
              " 'would': 60,\n",
              " 'which': 61,\n",
              " 'only': 62,\n",
              " 'story': 63,\n",
              " 'really': 64,\n",
              " 'see': 65,\n",
              " 'had': 66,\n",
              " 'their': 67,\n",
              " 'can': 68,\n",
              " 'me': 69,\n",
              " 'were': 70,\n",
              " 'well': 71,\n",
              " 'than': 72,\n",
              " 'we': 73,\n",
              " 'much': 74,\n",
              " 'get': 75,\n",
              " 'been': 76,\n",
              " 'bad': 77,\n",
              " 'will': 78,\n",
              " 'also': 79,\n",
              " 'do': 80,\n",
              " 'into': 81,\n",
              " 'other': 82,\n",
              " 'great': 83,\n",
              " 'first': 84,\n",
              " 'people': 85,\n",
              " 'because': 86,\n",
              " 'him': 87,\n",
              " 'how': 88,\n",
              " 'most': 89,\n",
              " \"don't\": 90,\n",
              " 'made': 91,\n",
              " 'then': 92,\n",
              " 'its': 93,\n",
              " 'make': 94,\n",
              " 'way': 95,\n",
              " 'them': 96,\n",
              " 'could': 97,\n",
              " 'too': 98,\n",
              " 'any': 99,\n",
              " 'after': 100,\n",
              " 'movies': 101,\n",
              " 'think': 102,\n",
              " 'characters': 103,\n",
              " 'watch': 104,\n",
              " 'two': 105,\n",
              " 'films': 106,\n",
              " 'seen': 107,\n",
              " 'character': 108,\n",
              " 'many': 109,\n",
              " 'being': 110,\n",
              " 'plot': 111,\n",
              " 'life': 112,\n",
              " 'acting': 113,\n",
              " 'never': 114,\n",
              " 'little': 115,\n",
              " 'best': 116,\n",
              " 'love': 117,\n",
              " 'where': 118,\n",
              " 'over': 119,\n",
              " 'did': 120,\n",
              " 'know': 121,\n",
              " 'show': 122,\n",
              " 'off': 123,\n",
              " 'ever': 124,\n",
              " 'does': 125,\n",
              " 'better': 126,\n",
              " 'man': 127,\n",
              " 'end': 128,\n",
              " 'your': 129,\n",
              " 'still': 130,\n",
              " 'here': 131,\n",
              " 'scene': 132,\n",
              " 'say': 133,\n",
              " 'these': 134,\n",
              " 'why': 135,\n",
              " 'while': 136,\n",
              " 'scenes': 137,\n",
              " 'such': 138,\n",
              " 'something': 139,\n",
              " 'go': 140,\n",
              " 'should': 141,\n",
              " 'through': 142,\n",
              " 'back': 143,\n",
              " 'real': 144,\n",
              " \"i'm\": 145,\n",
              " 'those': 146,\n",
              " 'watching': 147,\n",
              " 'though': 148,\n",
              " 'now': 149,\n",
              " \"doesn't\": 150,\n",
              " 'thing': 151,\n",
              " 'years': 152,\n",
              " 'old': 153,\n",
              " 'actors': 154,\n",
              " '10': 155,\n",
              " 'before': 156,\n",
              " 'another': 157,\n",
              " 'work': 158,\n",
              " 'new': 159,\n",
              " 'actually': 160,\n",
              " \"didn't\": 161,\n",
              " 'nothing': 162,\n",
              " 'funny': 163,\n",
              " 'makes': 164,\n",
              " 'look': 165,\n",
              " 'director': 166,\n",
              " 'few': 167,\n",
              " 'find': 168,\n",
              " 'going': 169,\n",
              " 'same': 170,\n",
              " 'again': 171,\n",
              " 'every': 172,\n",
              " 'lot': 173,\n",
              " 'part': 174,\n",
              " 'cast': 175,\n",
              " 'quite': 176,\n",
              " 'us': 177,\n",
              " 'pretty': 178,\n",
              " 'around': 179,\n",
              " 'down': 180,\n",
              " 'world': 181,\n",
              " 'things': 182,\n",
              " 'seems': 183,\n",
              " 'young': 184,\n",
              " 'want': 185,\n",
              " \"can't\": 186,\n",
              " 'got': 187,\n",
              " 'fact': 188,\n",
              " 'horror': 189,\n",
              " 'take': 190,\n",
              " 'however': 191,\n",
              " 'enough': 192,\n",
              " 'long': 193,\n",
              " 'both': 194,\n",
              " 'thought': 195,\n",
              " 'action': 196,\n",
              " 'may': 197,\n",
              " 'big': 198,\n",
              " \"i've\": 199,\n",
              " 'between': 200,\n",
              " 'give': 201,\n",
              " 'series': 202,\n",
              " \"that's\": 203,\n",
              " 'own': 204,\n",
              " 'original': 205,\n",
              " 'right': 206,\n",
              " 'without': 207,\n",
              " 'must': 208,\n",
              " 'comedy': 209,\n",
              " 'always': 210,\n",
              " 'point': 211,\n",
              " 'saw': 212,\n",
              " 'role': 213,\n",
              " 'come': 214,\n",
              " \"isn't\": 215,\n",
              " 'gets': 216,\n",
              " 'times': 217,\n",
              " 'least': 218,\n",
              " 'done': 219,\n",
              " 'almost': 220,\n",
              " 'interesting': 221,\n",
              " \"there's\": 222,\n",
              " 'bit': 223,\n",
              " 'family': 224,\n",
              " 'whole': 225,\n",
              " 'music': 226,\n",
              " 'guy': 227,\n",
              " 'script': 228,\n",
              " 'far': 229,\n",
              " 'feel': 230,\n",
              " 'anything': 231,\n",
              " 'making': 232,\n",
              " 'since': 233,\n",
              " 'minutes': 234,\n",
              " \"he's\": 235,\n",
              " 'might': 236,\n",
              " 'last': 237,\n",
              " 'performance': 238,\n",
              " 'probably': 239,\n",
              " '2': 240,\n",
              " 'kind': 241,\n",
              " 'away': 242,\n",
              " 'worst': 243,\n",
              " 'yet': 244,\n",
              " 'tv': 245,\n",
              " 'am': 246,\n",
              " 'rather': 247,\n",
              " 'girl': 248,\n",
              " 'sure': 249,\n",
              " 'hard': 250,\n",
              " 'day': 251,\n",
              " 'woman': 252,\n",
              " 'fun': 253,\n",
              " 'found': 254,\n",
              " 'although': 255,\n",
              " 'played': 256,\n",
              " 'anyone': 257,\n",
              " 'each': 258,\n",
              " 'having': 259,\n",
              " 'especially': 260,\n",
              " 'course': 261,\n",
              " 'looking': 262,\n",
              " 'believe': 263,\n",
              " 'our': 264,\n",
              " 'comes': 265,\n",
              " 'screen': 266,\n",
              " 'trying': 267,\n",
              " 'book': 268,\n",
              " 'set': 269,\n",
              " 'put': 270,\n",
              " 'place': 271,\n",
              " 'goes': 272,\n",
              " 'looks': 273,\n",
              " 'reason': 274,\n",
              " 'maybe': 275,\n",
              " 'ending': 276,\n",
              " 'money': 277,\n",
              " 'different': 278,\n",
              " 'true': 279,\n",
              " 'actor': 280,\n",
              " 'once': 281,\n",
              " 'sense': 282,\n",
              " 'dvd': 283,\n",
              " 'everything': 284,\n",
              " 'year': 285,\n",
              " 'shows': 286,\n",
              " 'main': 287,\n",
              " 'someone': 288,\n",
              " 'job': 289,\n",
              " \"wasn't\": 290,\n",
              " 'together': 291,\n",
              " 'worth': 292,\n",
              " 'three': 293,\n",
              " 'watched': 294,\n",
              " 'plays': 295,\n",
              " 'seem': 296,\n",
              " 'instead': 297,\n",
              " 'play': 298,\n",
              " 'said': 299,\n",
              " 'later': 300,\n",
              " 'house': 301,\n",
              " 'american': 302,\n",
              " 'takes': 303,\n",
              " 'effects': 304,\n",
              " '1': 305,\n",
              " 'left': 306,\n",
              " 'john': 307,\n",
              " 'audience': 308,\n",
              " 'himself': 309,\n",
              " 'version': 310,\n",
              " 'everyone': 311,\n",
              " 'during': 312,\n",
              " 'night': 313,\n",
              " 'high': 314,\n",
              " 'beautiful': 315,\n",
              " 'star': 316,\n",
              " 'seeing': 317,\n",
              " 'war': 318,\n",
              " 'special': 319,\n",
              " 'half': 320,\n",
              " 'idea': 321,\n",
              " 'wife': 322,\n",
              " 'excellent': 323,\n",
              " 'shot': 324,\n",
              " 'mind': 325,\n",
              " 'nice': 326,\n",
              " 'second': 327,\n",
              " 'less': 328,\n",
              " 'else': 329,\n",
              " 'simply': 330,\n",
              " 'father': 331,\n",
              " 'black': 332,\n",
              " 'read': 333,\n",
              " 'help': 334,\n",
              " 'death': 335,\n",
              " 'completely': 336,\n",
              " 'men': 337,\n",
              " \"you're\": 338,\n",
              " 'home': 339,\n",
              " 'short': 340,\n",
              " 'poor': 341,\n",
              " 'fan': 342,\n",
              " '3': 343,\n",
              " 'given': 344,\n",
              " 'either': 345,\n",
              " 'wrong': 346,\n",
              " 'used': 347,\n",
              " 'line': 348,\n",
              " 'dead': 349,\n",
              " 'need': 350,\n",
              " 'top': 351,\n",
              " 'boring': 352,\n",
              " 'kids': 353,\n",
              " 'try': 354,\n",
              " 'enjoy': 355,\n",
              " 'rest': 356,\n",
              " 'budget': 357,\n",
              " 'women': 358,\n",
              " 'classic': 359,\n",
              " 'performances': 360,\n",
              " 'low': 361,\n",
              " 'production': 362,\n",
              " 'hollywood': 363,\n",
              " 'along': 364,\n",
              " 'use': 365,\n",
              " 'full': 366,\n",
              " 'until': 367,\n",
              " 'friends': 368,\n",
              " 'awful': 369,\n",
              " 'camera': 370,\n",
              " 'video': 371,\n",
              " 'next': 372,\n",
              " 'start': 373,\n",
              " 'tell': 374,\n",
              " 'truly': 375,\n",
              " 'sex': 376,\n",
              " 'moments': 377,\n",
              " 'stupid': 378,\n",
              " 'mean': 379,\n",
              " 'stars': 380,\n",
              " 'came': 381,\n",
              " 'perhaps': 382,\n",
              " 'remember': 383,\n",
              " 'recommend': 384,\n",
              " 'getting': 385,\n",
              " 'small': 386,\n",
              " 'let': 387,\n",
              " 'couple': 388,\n",
              " 'understand': 389,\n",
              " 'wonderful': 390,\n",
              " 'school': 391,\n",
              " 'written': 392,\n",
              " 'perfect': 393,\n",
              " 'face': 394,\n",
              " 'terrible': 395,\n",
              " 'episode': 396,\n",
              " 'playing': 397,\n",
              " 'name': 398,\n",
              " 'keep': 399,\n",
              " 'style': 400,\n",
              " 'doing': 401,\n",
              " 'early': 402,\n",
              " 'definitely': 403,\n",
              " 'often': 404,\n",
              " 'gives': 405,\n",
              " 'others': 406,\n",
              " 'human': 407,\n",
              " 'lines': 408,\n",
              " 'become': 409,\n",
              " 'felt': 410,\n",
              " 'dialogue': 411,\n",
              " 'piece': 412,\n",
              " 'head': 413,\n",
              " 'itself': 414,\n",
              " 'lost': 415,\n",
              " 'person': 416,\n",
              " 'live': 417,\n",
              " 'finally': 418,\n",
              " 'liked': 419,\n",
              " 'supposed': 420,\n",
              " 'yes': 421,\n",
              " \"couldn't\": 422,\n",
              " 'boy': 423,\n",
              " 'case': 424,\n",
              " 'title': 425,\n",
              " 'against': 426,\n",
              " 'worse': 427,\n",
              " 'sort': 428,\n",
              " 'went': 429,\n",
              " 'cinema': 430,\n",
              " 'white': 431,\n",
              " 'entire': 432,\n",
              " 'picture': 433,\n",
              " 'evil': 434,\n",
              " 'mr': 435,\n",
              " 'certainly': 436,\n",
              " 'entertaining': 437,\n",
              " 'oh': 438,\n",
              " 'absolutely': 439,\n",
              " 'hope': 440,\n",
              " 'problem': 441,\n",
              " \"she's\": 442,\n",
              " 'beginning': 443,\n",
              " 'called': 444,\n",
              " 'overall': 445,\n",
              " 'waste': 446,\n",
              " 'fans': 447,\n",
              " 'killer': 448,\n",
              " 'drama': 449,\n",
              " 'mother': 450,\n",
              " 'laugh': 451,\n",
              " 'based': 452,\n",
              " 'loved': 453,\n",
              " 'several': 454,\n",
              " '5': 455,\n",
              " 'direction': 456,\n",
              " 'care': 457,\n",
              " 'under': 458,\n",
              " 'turn': 459,\n",
              " 'despite': 460,\n",
              " 'example': 461,\n",
              " 'already': 462,\n",
              " 'unfortunately': 463,\n",
              " 'friend': 464,\n",
              " 'becomes': 465,\n",
              " \"i'd\": 466,\n",
              " 'throughout': 467,\n",
              " 'children': 468,\n",
              " 'dark': 469,\n",
              " 'heart': 470,\n",
              " 'seemed': 471,\n",
              " '4': 472,\n",
              " 'wanted': 473,\n",
              " 'totally': 474,\n",
              " '\\x96': 475,\n",
              " 'final': 476,\n",
              " 'lives': 477,\n",
              " 'guys': 478,\n",
              " 'lead': 479,\n",
              " 'humor': 480,\n",
              " 'quality': 481,\n",
              " 'amazing': 482,\n",
              " 'history': 483,\n",
              " 'sound': 484,\n",
              " 'son': 485,\n",
              " 'wants': 486,\n",
              " \"you'll\": 487,\n",
              " 'art': 488,\n",
              " 'guess': 489,\n",
              " 'b': 490,\n",
              " 'writing': 491,\n",
              " 'close': 492,\n",
              " 'able': 493,\n",
              " 'tries': 494,\n",
              " 'fine': 495,\n",
              " 'flick': 496,\n",
              " 'past': 497,\n",
              " 'side': 498,\n",
              " 'days': 499,\n",
              " 'behind': 500,\n",
              " 'turns': 501,\n",
              " 'game': 502,\n",
              " 'hand': 503,\n",
              " 'sometimes': 504,\n",
              " 'works': 505,\n",
              " 'soon': 506,\n",
              " 'kill': 507,\n",
              " 'gave': 508,\n",
              " 'eyes': 509,\n",
              " 'etc': 510,\n",
              " 'enjoyed': 511,\n",
              " 'genre': 512,\n",
              " 'horrible': 513,\n",
              " 'favorite': 514,\n",
              " 'directed': 515,\n",
              " \"won't\": 516,\n",
              " 'run': 517,\n",
              " 'starts': 518,\n",
              " 'child': 519,\n",
              " 'viewer': 520,\n",
              " \"they're\": 521,\n",
              " 'michael': 522,\n",
              " 'town': 523,\n",
              " 'act': 524,\n",
              " 'car': 525,\n",
              " 'late': 526,\n",
              " 'expect': 527,\n",
              " 'obviously': 528,\n",
              " 'thinking': 529,\n",
              " 'themselves': 530,\n",
              " 'actress': 531,\n",
              " 'blood': 532,\n",
              " 'stuff': 533,\n",
              " 'decent': 534,\n",
              " 'except': 535,\n",
              " 'voice': 536,\n",
              " 'anyway': 537,\n",
              " 'brilliant': 538,\n",
              " 'hour': 539,\n",
              " 'city': 540,\n",
              " 'self': 541,\n",
              " 'parts': 542,\n",
              " 'highly': 543,\n",
              " 'feeling': 544,\n",
              " 'fight': 545,\n",
              " 'stories': 546,\n",
              " 'myself': 547,\n",
              " 'girls': 548,\n",
              " 'moment': 549,\n",
              " 'roles': 550,\n",
              " 'says': 551,\n",
              " 'heard': 552,\n",
              " 'kid': 553,\n",
              " 'matter': 554,\n",
              " 'killed': 555,\n",
              " 'type': 556,\n",
              " 'leave': 557,\n",
              " 'violence': 558,\n",
              " 'strong': 559,\n",
              " 'particularly': 560,\n",
              " 'age': 561,\n",
              " 'took': 562,\n",
              " 'slow': 563,\n",
              " 'happened': 564,\n",
              " 'cannot': 565,\n",
              " 'police': 566,\n",
              " 'obvious': 567,\n",
              " 'please': 568,\n",
              " 'writer': 569,\n",
              " 'known': 570,\n",
              " \"wouldn't\": 571,\n",
              " 'stop': 572,\n",
              " 'living': 573,\n",
              " 'daughter': 574,\n",
              " 's': 575,\n",
              " 'hit': 576,\n",
              " 'murder': 577,\n",
              " 'cut': 578,\n",
              " 'god': 579,\n",
              " 'happens': 580,\n",
              " 'brother': 581,\n",
              " 'extremely': 582,\n",
              " 'lack': 583,\n",
              " 'experience': 584,\n",
              " 'involved': 585,\n",
              " 'happen': 586,\n",
              " 'coming': 587,\n",
              " 'score': 588,\n",
              " 'chance': 589,\n",
              " 'wonder': 590,\n",
              " 'hell': 591,\n",
              " 'told': 592,\n",
              " 'crap': 593,\n",
              " 'simple': 594,\n",
              " 'save': 595,\n",
              " 'including': 596,\n",
              " 'james': 597,\n",
              " 'alone': 598,\n",
              " 'gore': 599,\n",
              " \"film's\": 600,\n",
              " 'number': 601,\n",
              " 'group': 602,\n",
              " 'attempt': 603,\n",
              " 'career': 604,\n",
              " 'possible': 605,\n",
              " 'ok': 606,\n",
              " 'seriously': 607,\n",
              " 'none': 608,\n",
              " 'scary': 609,\n",
              " 'released': 610,\n",
              " 'complete': 611,\n",
              " 'ago': 612,\n",
              " 'looked': 613,\n",
              " 'cinematography': 614,\n",
              " 'interest': 615,\n",
              " 'song': 616,\n",
              " 'opening': 617,\n",
              " 'taken': 618,\n",
              " 'jokes': 619,\n",
              " 'usually': 620,\n",
              " 'shown': 621,\n",
              " 'hilarious': 622,\n",
              " 'exactly': 623,\n",
              " 'musical': 624,\n",
              " 'running': 625,\n",
              " 'reality': 626,\n",
              " \"i'll\": 627,\n",
              " 'sad': 628,\n",
              " 'light': 629,\n",
              " 'ends': 630,\n",
              " 'whose': 631,\n",
              " 'body': 632,\n",
              " 'cool': 633,\n",
              " 'yourself': 634,\n",
              " 'somewhat': 635,\n",
              " 'today': 636,\n",
              " 'level': 637,\n",
              " 'ridiculous': 638,\n",
              " 'view': 639,\n",
              " 'room': 640,\n",
              " 'english': 641,\n",
              " 'started': 642,\n",
              " 'across': 643,\n",
              " 'annoying': 644,\n",
              " 'relationship': 645,\n",
              " 'robert': 646,\n",
              " 'opinion': 647,\n",
              " 'hours': 648,\n",
              " 'wish': 649,\n",
              " 'female': 650,\n",
              " 'david': 651,\n",
              " 'order': 652,\n",
              " 'serious': 653,\n",
              " 'talking': 654,\n",
              " 'finds': 655,\n",
              " 'novel': 656,\n",
              " 'talent': 657,\n",
              " 'ones': 658,\n",
              " 'taking': 659,\n",
              " 'usual': 660,\n",
              " 'hero': 661,\n",
              " 'word': 662,\n",
              " 'happy': 663,\n",
              " 'husband': 664,\n",
              " 'change': 665,\n",
              " 'call': 666,\n",
              " 'middle': 667,\n",
              " 'shots': 668,\n",
              " 'power': 669,\n",
              " 'mostly': 670,\n",
              " 'events': 671,\n",
              " 'five': 672,\n",
              " 'strange': 673,\n",
              " '7': 674,\n",
              " 'apparently': 675,\n",
              " 'huge': 676,\n",
              " 'important': 677,\n",
              " 'rating': 678,\n",
              " 'documentary': 679,\n",
              " 'non': 680,\n",
              " 'future': 681,\n",
              " 'disappointed': 682,\n",
              " 'knows': 683,\n",
              " 'saying': 684,\n",
              " 'modern': 685,\n",
              " 'basically': 686,\n",
              " 'single': 687,\n",
              " 'due': 688,\n",
              " 'knew': 689,\n",
              " 'supporting': 690,\n",
              " 'episodes': 691,\n",
              " 'major': 692,\n",
              " 'tells': 693,\n",
              " 'clearly': 694,\n",
              " 'attention': 695,\n",
              " 'sequence': 696,\n",
              " 'thriller': 697,\n",
              " 'four': 698,\n",
              " 'television': 699,\n",
              " 'songs': 700,\n",
              " 'comic': 701,\n",
              " 'turned': 702,\n",
              " 'jack': 703,\n",
              " 'country': 704,\n",
              " 'fast': 705,\n",
              " 'british': 706,\n",
              " 'words': 707,\n",
              " 'class': 708,\n",
              " 'bring': 709,\n",
              " '8': 710,\n",
              " 'silly': 711,\n",
              " 'earth': 712,\n",
              " 'miss': 713,\n",
              " 'paul': 714,\n",
              " 'romantic': 715,\n",
              " 'whether': 716,\n",
              " 'easily': 717,\n",
              " 'straight': 718,\n",
              " 'king': 719,\n",
              " 'animation': 720,\n",
              " \"aren't\": 721,\n",
              " 'upon': 722,\n",
              " 'oscar': 723,\n",
              " 'problems': 724,\n",
              " 'beyond': 725,\n",
              " 'cheap': 726,\n",
              " 'enjoyable': 727,\n",
              " 'review': 728,\n",
              " 'needs': 729,\n",
              " 'eye': 730,\n",
              " 'mystery': 731,\n",
              " 'local': 732,\n",
              " 'entertainment': 733,\n",
              " 'talk': 734,\n",
              " 'moving': 735,\n",
              " 'predictable': 736,\n",
              " 'rock': 737,\n",
              " 'ten': 738,\n",
              " 'dull': 739,\n",
              " 'giving': 740,\n",
              " 'appears': 741,\n",
              " 'falls': 742,\n",
              " 'points': 743,\n",
              " 'similar': 744,\n",
              " 'message': 745,\n",
              " 'theater': 746,\n",
              " 'add': 747,\n",
              " 'hate': 748,\n",
              " 'sets': 749,\n",
              " 'begins': 750,\n",
              " 'near': 751,\n",
              " 'sister': 752,\n",
              " 'theme': 753,\n",
              " 'george': 754,\n",
              " 'herself': 755,\n",
              " 'release': 756,\n",
              " 'bunch': 757,\n",
              " 'mention': 758,\n",
              " 'stand': 759,\n",
              " 'using': 760,\n",
              " 'within': 761,\n",
              " 'above': 762,\n",
              " 'red': 763,\n",
              " 'lady': 764,\n",
              " 'richard': 765,\n",
              " 'die': 766,\n",
              " \"haven't\": 767,\n",
              " 'lots': 768,\n",
              " 'storyline': 769,\n",
              " 'surprised': 770,\n",
              " 'clear': 771,\n",
              " 'feels': 772,\n",
              " 'french': 773,\n",
              " 'showing': 774,\n",
              " 'actual': 775,\n",
              " 'tale': 776,\n",
              " 'named': 777,\n",
              " 'stay': 778,\n",
              " 'fantastic': 779,\n",
              " 'sequel': 780,\n",
              " 'tried': 781,\n",
              " 'easy': 782,\n",
              " 'feature': 783,\n",
              " 'follow': 784,\n",
              " 'weak': 785,\n",
              " 'york': 786,\n",
              " 'ways': 787,\n",
              " 'working': 788,\n",
              " 'sorry': 789,\n",
              " 'comments': 790,\n",
              " 'team': 791,\n",
              " 'period': 792,\n",
              " 'nearly': 793,\n",
              " \"what's\": 794,\n",
              " 'season': 795,\n",
              " 'filmed': 796,\n",
              " 'figure': 797,\n",
              " 'gone': 798,\n",
              " 'check': 799,\n",
              " \"'\": 800,\n",
              " 'certain': 801,\n",
              " 'minute': 802,\n",
              " 'effort': 803,\n",
              " 'material': 804,\n",
              " 're': 805,\n",
              " 'leads': 806,\n",
              " 'somehow': 807,\n",
              " 'among': 808,\n",
              " 'peter': 809,\n",
              " 'editing': 810,\n",
              " 'famous': 811,\n",
              " 'means': 812,\n",
              " 'viewers': 813,\n",
              " 'dialog': 814,\n",
              " 'elements': 815,\n",
              " '9': 816,\n",
              " 'soundtrack': 817,\n",
              " 'doubt': 818,\n",
              " 'general': 819,\n",
              " 'sequences': 820,\n",
              " 'avoid': 821,\n",
              " 'greatest': 822,\n",
              " 'form': 823,\n",
              " 'fall': 824,\n",
              " 'tom': 825,\n",
              " 'brought': 826,\n",
              " 'suspense': 827,\n",
              " 'viewing': 828,\n",
              " 'realistic': 829,\n",
              " 'particular': 830,\n",
              " 'buy': 831,\n",
              " 'typical': 832,\n",
              " 'space': 833,\n",
              " 'kept': 834,\n",
              " 'imagine': 835,\n",
              " 'forget': 836,\n",
              " 'third': 837,\n",
              " 'dance': 838,\n",
              " 'crime': 839,\n",
              " 'lame': 840,\n",
              " 'note': 841,\n",
              " 'whatever': 842,\n",
              " 'poorly': 843,\n",
              " 'lee': 844,\n",
              " 'atmosphere': 845,\n",
              " 'learn': 846,\n",
              " 'hear': 847,\n",
              " 't': 848,\n",
              " 'rent': 849,\n",
              " 'move': 850,\n",
              " 'expected': 851,\n",
              " 'average': 852,\n",
              " 'needed': 853,\n",
              " 'wait': 854,\n",
              " 'believable': 855,\n",
              " 'sit': 856,\n",
              " 'indeed': 857,\n",
              " 'parents': 858,\n",
              " 'street': 859,\n",
              " 'possibly': 860,\n",
              " 'became': 861,\n",
              " 'stage': 862,\n",
              " 'deal': 863,\n",
              " 'decided': 864,\n",
              " 'reading': 865,\n",
              " 'otherwise': 866,\n",
              " 'eventually': 867,\n",
              " 'nature': 868,\n",
              " 'screenplay': 869,\n",
              " 'de': 870,\n",
              " 'meets': 871,\n",
              " 'sexual': 872,\n",
              " 'surprise': 873,\n",
              " 'premise': 874,\n",
              " 'subject': 875,\n",
              " 'free': 876,\n",
              " \"you've\": 877,\n",
              " \"who's\": 878,\n",
              " 'hot': 879,\n",
              " 'baby': 880,\n",
              " 'joe': 881,\n",
              " '20': 882,\n",
              " 'killing': 883,\n",
              " 'disney': 884,\n",
              " 'nor': 885,\n",
              " \"let's\": 886,\n",
              " 'leaves': 887,\n",
              " 'romance': 888,\n",
              " 'okay': 889,\n",
              " 'question': 890,\n",
              " 'reviews': 891,\n",
              " 'begin': 892,\n",
              " 'credits': 893,\n",
              " 'dramatic': 894,\n",
              " 'society': 895,\n",
              " 'difficult': 896,\n",
              " 'shame': 897,\n",
              " 'forward': 898,\n",
              " 'male': 899,\n",
              " 'write': 900,\n",
              " 'laughs': 901,\n",
              " 'meet': 902,\n",
              " 'memorable': 903,\n",
              " 'unless': 904,\n",
              " 'truth': 905,\n",
              " 'perfectly': 906,\n",
              " 'realize': 907,\n",
              " 'zombie': 908,\n",
              " 'dr': 909,\n",
              " 'japanese': 910,\n",
              " 'earlier': 911,\n",
              " 'crazy': 912,\n",
              " 'superb': 913,\n",
              " 'sounds': 914,\n",
              " 'interested': 915,\n",
              " 'directors': 916,\n",
              " 'badly': 917,\n",
              " 'writers': 918,\n",
              " 'dream': 919,\n",
              " 'air': 920,\n",
              " 'open': 921,\n",
              " 'imdb': 922,\n",
              " 'footage': 923,\n",
              " 'powerful': 924,\n",
              " 'forced': 925,\n",
              " 'development': 926,\n",
              " 'situation': 927,\n",
              " 'emotional': 928,\n",
              " 'monster': 929,\n",
              " 'beauty': 930,\n",
              " 'worked': 931,\n",
              " 'fantasy': 932,\n",
              " 'acted': 933,\n",
              " 'whom': 934,\n",
              " 'directing': 935,\n",
              " 'older': 936,\n",
              " 'deep': 937,\n",
              " 'incredibly': 938,\n",
              " 'weird': 939,\n",
              " 'america': 940,\n",
              " 'quickly': 941,\n",
              " 'hands': 942,\n",
              " 'effect': 943,\n",
              " 'box': 944,\n",
              " 'joke': 945,\n",
              " 'brings': 946,\n",
              " 'leading': 947,\n",
              " 'plus': 948,\n",
              " 'political': 949,\n",
              " 'cheesy': 950,\n",
              " 'total': 951,\n",
              " 'towards': 952,\n",
              " 'mark': 953,\n",
              " 'sci': 954,\n",
              " 'comment': 955,\n",
              " 'admit': 956,\n",
              " 'mess': 957,\n",
              " 'ask': 958,\n",
              " 'fi': 959,\n",
              " 'fighting': 960,\n",
              " 'background': 961,\n",
              " 'cop': 962,\n",
              " 'appear': 963,\n",
              " 'setting': 964,\n",
              " 'creepy': 965,\n",
              " 'previous': 966,\n",
              " 'plenty': 967,\n",
              " 'battle': 968,\n",
              " 'rate': 969,\n",
              " 'e': 970,\n",
              " 'front': 971,\n",
              " 'personal': 972,\n",
              " 'unique': 973,\n",
              " 'dumb': 974,\n",
              " 'result': 975,\n",
              " 'present': 976,\n",
              " 'casting': 977,\n",
              " 'masterpiece': 978,\n",
              " 'return': 979,\n",
              " 'fire': 980,\n",
              " 'potential': 981,\n",
              " 'fails': 982,\n",
              " 'deserves': 983,\n",
              " 'features': 984,\n",
              " 'expecting': 985,\n",
              " 'various': 986,\n",
              " 'create': 987,\n",
              " 'reasons': 988,\n",
              " 'nudity': 989,\n",
              " 'apart': 990,\n",
              " 'match': 991,\n",
              " 'dog': 992,\n",
              " 'keeps': 993,\n",
              " 'business': 994,\n",
              " 'gay': 995,\n",
              " 'list': 996,\n",
              " 'married': 997,\n",
              " 'co': 998,\n",
              " 'outside': 999,\n",
              " 'inside': 1000,\n",
              " ...}"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2GgPOuSzKMRA"
      },
      "source": [
        "#### Prepare Training and Test Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8o8fG3FtKMRA"
      },
      "source": [
        "Get the word index for each of the word in the review"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G9m65RFCVXCd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "107ac739-57f3-4721-a881-0d59c3ddfca7"
      },
      "source": [
        "X_train[0:1]"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "23311    \"This movie is just plain dumb.<br /><br />Fro...\n",
              "Name: review, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fNQIpYPKKMRB"
      },
      "source": [
        "X_train = t.texts_to_sequences(X_train.tolist())"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xh1nDZFDVlB8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed3ae641-81d5-4578-8154-12d321536464"
      },
      "source": [
        "print(X_train[0:1])"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[12, 18, 7, 41, 1059, 974, 8, 8, 37, 2, 977, 5, 2845, 1, 15, 1856, 4247, 6, 2, 1, 1353, 2, 20, 7, 33, 3233, 9, 1605, 8653, 8, 8, 1856, 4247, 7, 29, 5, 1234, 1, 279, 1, 1017, 1, 3, 7946, 35, 270, 1280, 291, 6, 3352, 2, 731, 4247, 2001, 182, 990, 6, 75, 6, 2, 905, 12, 20, 501, 4247, 81, 4, 9825, 32, 3468, 87, 17, 77, 478, 35, 25, 71, 98, 974, 6, 75, 242, 17, 231, 29, 7, 36, 843, 1276, 13, 27, 1, 6, 4, 3694, 1238, 8, 8, 82, 542, 5, 2, 18, 25, 206, 44, 5, 2, 293, 4878, 298, 268, 1, 838, 31, 2, 1, 16, 1845, 40, 2, 77, 227, 35, 2554, 8105, 24, 1427, 9, 2, 143, 3, 2, 2349, 2001, 25, 8106, 1, 1, 7, 625, 180, 2, 1, 5, 2, 1302, 52, 2, 370, 7, 2637, 21, 39, 2368, 2976, 19, 442, 95, 119, 2, 498, 52, 2, 370, 2603, 143, 16, 4, 6452, 324, 2, 243, 1010, 191, 1, 2, 3694, 1238, 2, 77, 227, 5900, 4247, 3857, 4, 6665, 1559, 100, 264, 661, 535, 2, 6665, 286, 27, 14, 1512, 234, 500, 264, 227, 8, 8, 6, 28, 1297, 47, 70, 48, 221, 370, 2426, 3, 1537, 3, 2, 1697, 1977, 7, 36, 77, 13, 10, 208, 76, 107, 61, 7, 2, 62, 274, 13, 10, 216, 105, 743, 44, 5, 155]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Gix3lNmKMRD"
      },
      "source": [
        "X_test = t.texts_to_sequences(X_test)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hb9z28TZKMRF"
      },
      "source": [
        "How many words in each review?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O7maQ5kpxdfI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11ce7396-e4fe-4db2-9cf5-eee389d87bcd"
      },
      "source": [
        "len(X_train[200])"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "156"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fKmVWM5pKMRF"
      },
      "source": [
        "#### Pad Sequences - Important"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h5YfEUx2KMRI"
      },
      "source": [
        "#Define maximum number of words to consider in each review\n",
        "max_review_length = 300"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aeJeFjogKMRM"
      },
      "source": [
        "#Pad training and test reviews\n",
        "X_train = tf.keras.preprocessing.sequence.pad_sequences(X_train,\n",
        "                                                        maxlen=max_review_length,\n",
        "                                                        padding='pre')\n",
        "X_test = tf.keras.preprocessing.sequence.pad_sequences(X_test, \n",
        "                                                       maxlen=max_review_length, \n",
        "                                                       padding='pre')"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i4GLCWBOlztU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "788e6b37-4340-4951-bf41-b3cb9ba52728"
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20000, 300)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6QJqX-Z5wL-W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3fdf8f9b-d7c4-4a18-82f0-d0d53f534e4a"
      },
      "source": [
        "X_test.shape"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5000, 300)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HVteHr5IzS4I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "189b5ffc-da81-490a-fa0c-16507efabc3d"
      },
      "source": [
        "X_train[200]"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,   11,  212,   12,   18,   17,    4,  757,    5,  368,    3,\n",
              "        255,   62,  105,    5,  177, 2572,   44,    5,    2,  430,  529,\n",
              "         88,  633,   10,   14,    2,  406,   41, 1470,    3, 4210,   21,\n",
              "         88,  378,   10,   14,   71,   13,   14,   86,   10,  215,  420,\n",
              "          6,   28,  618,   36,  607,  686,   10,    7,    4,    4,   18,\n",
              "         13,    1,  189, 1560,    3,  125,    4, 1506,   50,  289,   47,\n",
              "        183,    6,   28,  157,   18,  587,   44,   38,   13,   98,    1,\n",
              "        609,   18,   71,   12,    7, 6484,    3,  205, 2840,    1,  125,\n",
              "          4,    1,  238,    3, 2745,    1,   45,    4,    1, 1933,  681,\n",
              "          9,  113,   11,  440,    6,   65,   51,    5,   96, 4734,    1,\n",
              "         14,    4,   50,  850,    3,    1,   14,   33,   56,  126,  850,\n",
              "          2, 1174, 2490,   14, 1616,    5,    2,  266,   11,  384,  317,\n",
              "         12,  496,   15,  487,   28, 3156,  367,    2,   53,  128,    2,\n",
              "       2003,   17,    1,    1,    3,    2,   18,   13,  114,  187, 1710,\n",
              "        882,  152,  612], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m7CMlSVYCHNA"
      },
      "source": [
        "#### Load Glove model\n",
        "\n",
        "We can use gensim library to load pre-trained Word2Vec or Glove models. For list of available models can be found at [this url](https://github.com/RaRe-Technologies/gensim-data)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C6cDJb-RR0nn"
      },
      "source": [
        "import gensim.downloader as api"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3DNgLyLgR3H_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5871eba7-5bb6-4439-9662-8093a3a04ed7"
      },
      "source": [
        "#Load Glove model (similar to Word2Vec)\n",
        "glove_model = api.load('glove-wiki-gigaword-50')"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[==================================================] 100.0% 66.0/66.0MB downloaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lewBKMuRR5W5"
      },
      "source": [
        "#Model vocabulary\n",
        "#glove_model.index2word"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K9jb8OpbJR91",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dac5b0f1-66dc-44b0-a175-39f202e57027"
      },
      "source": [
        "#Size of the model\n",
        "glove_model.vectors.shape"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(400000, 50)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tp64MQ8WJYL0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36366a37-32e2-4ee4-fcd0-960df822d568"
      },
      "source": [
        "#Embedding for word great\n",
        "glove_model['great']"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.026567,  1.3357  , -1.028   , -0.3729  ,  0.52012 , -0.12699 ,\n",
              "       -0.35433 ,  0.37824 , -0.29716 ,  0.093894, -0.034122,  0.92961 ,\n",
              "       -0.14023 , -0.63299 ,  0.020801, -0.21533 ,  0.96923 ,  0.47654 ,\n",
              "       -1.0039  , -0.24013 , -0.36325 , -0.004757, -0.5148  , -0.4626  ,\n",
              "        1.2447  , -1.8316  , -1.5581  , -0.37465 ,  0.53362 ,  0.20883 ,\n",
              "        3.2209  ,  0.64549 ,  0.37438 , -0.17657 , -0.024164,  0.33786 ,\n",
              "       -0.419   ,  0.40081 , -0.11449 ,  0.051232, -0.15205 ,  0.29855 ,\n",
              "       -0.44052 ,  0.11089 , -0.24633 ,  0.66251 , -0.26949 , -0.49658 ,\n",
              "       -0.41618 , -0.2549  ], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UTZqcuaqB2cl"
      },
      "source": [
        "#### Get Pre-trained Embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n3Ftgb1zSDvG"
      },
      "source": [
        "Pre-trained Glove model has 400,000 unique words (Vocabulary size). We do not need all the words. Moreover, we have to arrange word embeddings according to word index created by our tokenizers above. So we will extract word embeddings for only the words that we are interested in."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SbgVAzAPDl1O"
      },
      "source": [
        "#Embedding length based on selected model - we are using 50d here.\n",
        "embedding_vector_length = glove_model.vector_size"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kBQOS906KX0p"
      },
      "source": [
        "Initialize a embedding matrix which we will populate for our vocabulary words."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HPNcZC9PEA8v"
      },
      "source": [
        "#Initialize embedding matrix for our dataset with 10000+1 rows (1 for padding word)\n",
        "#and 50 columns (as embedding size is 50)\n",
        "embedding_matrix = np.zeros((desired_vocab_size  + 1, embedding_vector_length))"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SVaLTX2cTZ79"
      },
      "source": [
        "Load word vectors for each word in our vocabulary from from Glove pre-trained model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mufDrkM-EKlK"
      },
      "source": [
        "for word, i in sorted(t.word_index.items(),key=lambda x:x[1]):\n",
        "    if i > (desired_vocab_size+1):\n",
        "        break\n",
        "    try:\n",
        "        embedding_vector = glove_model[word] #Reading word's embedding from Glove model for a given word\n",
        "        embedding_matrix[i] = embedding_vector\n",
        "    except:\n",
        "        pass"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Ww5J3x_LGg3"
      },
      "source": [
        "We now have word embeddings for our vocabulary words from Glove model. We can now use it in our Model training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qeZNhU2ZEs1w"
      },
      "source": [
        "#embedding_matrix[2]"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wAOvV9C_KMRl"
      },
      "source": [
        "#### Build Model - Dense Layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pWtUZzM3KMRs"
      },
      "source": [
        "#Initialize model\n",
        "tf.keras.backend.clear_session()\n",
        "model = tf.keras.Sequential()"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rbo6eeNGMtWn"
      },
      "source": [
        "To handle, pre-trained embeddings, we will use Keras Embedding layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vUTG9uAMM-z3"
      },
      "source": [
        "model.add(tf.keras.layers.Embedding(desired_vocab_size + 1, #Vocablury size\n",
        "                                    embedding_vector_length, #Embedding size\n",
        "                                    weights=[embedding_matrix], #Embeddings taken from pre-trained model\n",
        "                                    trainable=False, #As embeddings are already available, we will not train this layer. It will act as lookup layer.\n",
        "                                    input_length=max_review_length) #Number of words in each review\n",
        "          )"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KKyc5UQSMDQG"
      },
      "source": [
        "Embedding Layer gives us 3D output ->\n",
        "[Batch_Size , Review Length , Embedding_Size]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ezX7QcD8NSmw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "804b02ad-764c-4fa0-a26b-ef1a2a94eb34"
      },
      "source": [
        "model.output"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<KerasTensor: shape=(None, 300, 50) dtype=float32 (created by layer 'embedding')>"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DF_wJp6sKMRv"
      },
      "source": [
        "Add Hidden layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iignS5XqKMRv"
      },
      "source": [
        "#Flatten the data as we will use Dense layers\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "\n",
        "#Add Hidden layers (Dense layers)\n",
        "model.add(tf.keras.layers.Dense(100, activation='relu', input_shape=()))\n",
        "model.add(tf.keras.layers.BatchNormalization())\n",
        "model.add(tf.keras.layers.Dense(50, activation='relu'))\n",
        "model.add(tf.keras.layers.BatchNormalization())\n",
        "model.add(tf.keras.layers.Dense(25, activation='relu'))\n",
        "model.add(tf.keras.layers.Dropout(0.25))"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q8ua5Dj8LVk2"
      },
      "source": [
        "Add Output layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9esFq2mNZfFZ"
      },
      "source": [
        "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GobXBLHXKMR9"
      },
      "source": [
        "#Compile the model\n",
        "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iueK1G3pOznW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d466e1c8-d144-4f8d-e302-c7c5d80e7d10"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 300, 50)           500050    \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 15000)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 100)               1500100   \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 100)               400       \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 50)                5050      \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 50)                200       \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 25)                1275      \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 25)                0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 26        \n",
            "=================================================================\n",
            "Total params: 2,007,101\n",
            "Trainable params: 1,506,751\n",
            "Non-trainable params: 500,350\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j_aH5TX5KMSA"
      },
      "source": [
        "##### Train Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "AV3TceqjKMSC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b50ffc72-e2d2-46e4-ec8d-484675689f5d"
      },
      "source": [
        "model.fit(X_train,y_train,\n",
        "          epochs=20,\n",
        "          batch_size=32,          \n",
        "          validation_data=(X_test, y_test))"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "625/625 [==============================] - 12s 18ms/step - loss: 0.6302 - accuracy: 0.6516 - val_loss: 0.5722 - val_accuracy: 0.6992\n",
            "Epoch 2/20\n",
            "625/625 [==============================] - 11s 17ms/step - loss: 0.4900 - accuracy: 0.7634 - val_loss: 0.6095 - val_accuracy: 0.6870\n",
            "Epoch 3/20\n",
            "625/625 [==============================] - 11s 17ms/step - loss: 0.3910 - accuracy: 0.8243 - val_loss: 0.6312 - val_accuracy: 0.6930\n",
            "Epoch 4/20\n",
            "625/625 [==============================] - 11s 17ms/step - loss: 0.3104 - accuracy: 0.8623 - val_loss: 0.8301 - val_accuracy: 0.6830\n",
            "Epoch 5/20\n",
            "625/625 [==============================] - 11s 18ms/step - loss: 0.2329 - accuracy: 0.9024 - val_loss: 0.9253 - val_accuracy: 0.6888\n",
            "Epoch 6/20\n",
            "625/625 [==============================] - 11s 17ms/step - loss: 0.1865 - accuracy: 0.9231 - val_loss: 1.0666 - val_accuracy: 0.6472\n",
            "Epoch 7/20\n",
            "625/625 [==============================] - 11s 17ms/step - loss: 0.1483 - accuracy: 0.9432 - val_loss: 1.1938 - val_accuracy: 0.6732\n",
            "Epoch 8/20\n",
            "625/625 [==============================] - 11s 17ms/step - loss: 0.1237 - accuracy: 0.9520 - val_loss: 1.2500 - val_accuracy: 0.6632\n",
            "Epoch 9/20\n",
            "625/625 [==============================] - 11s 17ms/step - loss: 0.1106 - accuracy: 0.9580 - val_loss: 1.4130 - val_accuracy: 0.6564\n",
            "Epoch 10/20\n",
            "625/625 [==============================] - 11s 17ms/step - loss: 0.0983 - accuracy: 0.9628 - val_loss: 1.4592 - val_accuracy: 0.6716\n",
            "Epoch 11/20\n",
            "625/625 [==============================] - 11s 17ms/step - loss: 0.0930 - accuracy: 0.9666 - val_loss: 1.4220 - val_accuracy: 0.6660\n",
            "Epoch 12/20\n",
            "625/625 [==============================] - 11s 17ms/step - loss: 0.0811 - accuracy: 0.9696 - val_loss: 1.5214 - val_accuracy: 0.6790\n",
            "Epoch 13/20\n",
            "625/625 [==============================] - 11s 17ms/step - loss: 0.0725 - accuracy: 0.9744 - val_loss: 1.6563 - val_accuracy: 0.6806\n",
            "Epoch 14/20\n",
            "625/625 [==============================] - 11s 17ms/step - loss: 0.0763 - accuracy: 0.9719 - val_loss: 1.5548 - val_accuracy: 0.6566\n",
            "Epoch 15/20\n",
            "625/625 [==============================] - 10s 17ms/step - loss: 0.0679 - accuracy: 0.9756 - val_loss: 1.5604 - val_accuracy: 0.6570\n",
            "Epoch 16/20\n",
            "625/625 [==============================] - 11s 17ms/step - loss: 0.0569 - accuracy: 0.9797 - val_loss: 1.7327 - val_accuracy: 0.6786\n",
            "Epoch 17/20\n",
            "625/625 [==============================] - 11s 18ms/step - loss: 0.0568 - accuracy: 0.9787 - val_loss: 1.6407 - val_accuracy: 0.6580\n",
            "Epoch 18/20\n",
            "625/625 [==============================] - 11s 17ms/step - loss: 0.0563 - accuracy: 0.9792 - val_loss: 1.6577 - val_accuracy: 0.6624\n",
            "Epoch 19/20\n",
            "625/625 [==============================] - 11s 17ms/step - loss: 0.0548 - accuracy: 0.9810 - val_loss: 1.6539 - val_accuracy: 0.6776\n",
            "Epoch 20/20\n",
            "625/625 [==============================] - 11s 17ms/step - loss: 0.0404 - accuracy: 0.9868 - val_loss: 1.9308 - val_accuracy: 0.6772\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f2db5b22590>"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2NvjDJo7OYOb"
      },
      "source": [
        "#### Building a CNN Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PlhUrG_EO2Ga"
      },
      "source": [
        "Start a model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tc0ZANd3OaWs"
      },
      "source": [
        "model2 = tf.keras.Sequential()"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eRX6YC7_O3to"
      },
      "source": [
        "Add Embedding layer to handle Word2Vec"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gF2fufQFOx2w"
      },
      "source": [
        "model2.add(tf.keras.layers.Embedding(desired_vocab_size + 1, #Vocablury size\n",
        "                                    embedding_vector_length, #Embedding size\n",
        "                                    weights=[embedding_matrix], #Embeddings taken from pre-trained model\n",
        "                                    trainable=False, #As embeddings are already available, we will not train this layer. It will act as lookup layer.\n",
        "                                    input_length=max_review_length) #Number of words in each review\n",
        "          )"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VJRM3ICZO8lD"
      },
      "source": [
        "Add Conv1D hidden layers : As our text data is 2D (number of words, Embedding size), we will use Conv1D in this case (compared to Conv2D with images which are 3D)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3a03h-_9OmqL"
      },
      "source": [
        "#Add first convolutional layer\n",
        "model2.add(tf.keras.layers.Conv1D(32, #Number of filters \n",
        "                                 kernel_size=(3), #Size of the filter\n",
        "                                 strides=1,\n",
        "                                 activation='relu'))\n",
        "\n",
        "#normalize data\n",
        "model2.add(tf.keras.layers.BatchNormalization())\n",
        "\n",
        "#Add second convolutional layer\n",
        "model2.add(tf.keras.layers.Conv1D(64, kernel_size=(3), strides=2))\n",
        "model2.add(tf.keras.layers.ReLU())\n",
        "\n",
        "#normalize data\n",
        "model2.add(tf.keras.layers.BatchNormalization())"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fKJbqsCNPTLr"
      },
      "source": [
        "#Use Global Average Pooling\n",
        "model2.add(tf.keras.layers.GlobalAveragePooling1D())\n",
        "\n",
        "#Output layer\n",
        "model2.add(tf.keras.layers.Dense(1, activation='sigmoid'))"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FZCe3ghEPjyx"
      },
      "source": [
        "#Compile the model\n",
        "model2.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ekq97ri0Pne2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99fb38ae-d298-4484-b22b-69c1529f87fe"
      },
      "source": [
        "model2.summary()"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 300, 50)           500050    \n",
            "_________________________________________________________________\n",
            "conv1d (Conv1D)              (None, 298, 32)           4832      \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 298, 32)           128       \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 148, 64)           6208      \n",
            "_________________________________________________________________\n",
            "re_lu (ReLU)                 (None, 148, 64)           0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 148, 64)           256       \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d (Gl (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 511,539\n",
            "Trainable params: 11,297\n",
            "Non-trainable params: 500,242\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0w0oGtKpPxkp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd2e3c83-0666-434c-810a-15fc1cd74975"
      },
      "source": [
        "model2.fit(X_train,y_train,\n",
        "          epochs=25,\n",
        "          batch_size=32,          \n",
        "          validation_data=(X_test, y_test))"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "625/625 [==============================] - 21s 32ms/step - loss: 0.4862 - accuracy: 0.7694 - val_loss: 0.3990 - val_accuracy: 0.8280\n",
            "Epoch 2/25\n",
            "625/625 [==============================] - 20s 32ms/step - loss: 0.3802 - accuracy: 0.8368 - val_loss: 0.3540 - val_accuracy: 0.8480\n",
            "Epoch 3/25\n",
            "625/625 [==============================] - 20s 33ms/step - loss: 0.3452 - accuracy: 0.8551 - val_loss: 0.3690 - val_accuracy: 0.8422\n",
            "Epoch 4/25\n",
            "625/625 [==============================] - 20s 32ms/step - loss: 0.3265 - accuracy: 0.8642 - val_loss: 0.3402 - val_accuracy: 0.8602\n",
            "Epoch 5/25\n",
            "625/625 [==============================] - 20s 32ms/step - loss: 0.3073 - accuracy: 0.8712 - val_loss: 0.5299 - val_accuracy: 0.7766\n",
            "Epoch 6/25\n",
            "625/625 [==============================] - 20s 32ms/step - loss: 0.3002 - accuracy: 0.8773 - val_loss: 0.3517 - val_accuracy: 0.8528\n",
            "Epoch 7/25\n",
            "625/625 [==============================] - 20s 32ms/step - loss: 0.2864 - accuracy: 0.8850 - val_loss: 0.3541 - val_accuracy: 0.8494\n",
            "Epoch 8/25\n",
            "625/625 [==============================] - 22s 36ms/step - loss: 0.2737 - accuracy: 0.8874 - val_loss: 0.3966 - val_accuracy: 0.8384\n",
            "Epoch 9/25\n",
            "625/625 [==============================] - 20s 33ms/step - loss: 0.2642 - accuracy: 0.8918 - val_loss: 0.5049 - val_accuracy: 0.7878\n",
            "Epoch 10/25\n",
            "625/625 [==============================] - 21s 33ms/step - loss: 0.2558 - accuracy: 0.8944 - val_loss: 0.5569 - val_accuracy: 0.7848\n",
            "Epoch 11/25\n",
            "625/625 [==============================] - 21s 33ms/step - loss: 0.2432 - accuracy: 0.8995 - val_loss: 0.3999 - val_accuracy: 0.8338\n",
            "Epoch 12/25\n",
            "625/625 [==============================] - 21s 33ms/step - loss: 0.2407 - accuracy: 0.8974 - val_loss: 0.3710 - val_accuracy: 0.8438\n",
            "Epoch 13/25\n",
            "625/625 [==============================] - 21s 34ms/step - loss: 0.2298 - accuracy: 0.9051 - val_loss: 0.3676 - val_accuracy: 0.8490\n",
            "Epoch 14/25\n",
            "625/625 [==============================] - 21s 34ms/step - loss: 0.2188 - accuracy: 0.9097 - val_loss: 0.6082 - val_accuracy: 0.7784\n",
            "Epoch 15/25\n",
            "625/625 [==============================] - 21s 34ms/step - loss: 0.2109 - accuracy: 0.9141 - val_loss: 0.5162 - val_accuracy: 0.8118\n",
            "Epoch 16/25\n",
            "625/625 [==============================] - 21s 33ms/step - loss: 0.2056 - accuracy: 0.9182 - val_loss: 0.4955 - val_accuracy: 0.8246\n",
            "Epoch 17/25\n",
            "625/625 [==============================] - 21s 34ms/step - loss: 0.2001 - accuracy: 0.9179 - val_loss: 0.4099 - val_accuracy: 0.8540\n",
            "Epoch 18/25\n",
            "625/625 [==============================] - 21s 34ms/step - loss: 0.1952 - accuracy: 0.9176 - val_loss: 0.4209 - val_accuracy: 0.8394\n",
            "Epoch 19/25\n",
            "625/625 [==============================] - 21s 33ms/step - loss: 0.1832 - accuracy: 0.9248 - val_loss: 0.4328 - val_accuracy: 0.8420\n",
            "Epoch 20/25\n",
            "625/625 [==============================] - 21s 34ms/step - loss: 0.1800 - accuracy: 0.9270 - val_loss: 0.4186 - val_accuracy: 0.8448\n",
            "Epoch 21/25\n",
            "625/625 [==============================] - 21s 33ms/step - loss: 0.1711 - accuracy: 0.9312 - val_loss: 0.4378 - val_accuracy: 0.8346\n",
            "Epoch 22/25\n",
            "625/625 [==============================] - 21s 34ms/step - loss: 0.1667 - accuracy: 0.9341 - val_loss: 0.4281 - val_accuracy: 0.8434\n",
            "Epoch 23/25\n",
            "625/625 [==============================] - 21s 34ms/step - loss: 0.1620 - accuracy: 0.9368 - val_loss: 0.4561 - val_accuracy: 0.8308\n",
            "Epoch 24/25\n",
            "625/625 [==============================] - 21s 34ms/step - loss: 0.1649 - accuracy: 0.9348 - val_loss: 0.4210 - val_accuracy: 0.8418\n",
            "Epoch 25/25\n",
            "625/625 [==============================] - 21s 34ms/step - loss: 0.1501 - accuracy: 0.9419 - val_loss: 0.4435 - val_accuracy: 0.8400\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f2db58a87d0>"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BxD8neFu8Sq9"
      },
      "source": [
        ""
      ],
      "execution_count": 67,
      "outputs": []
    }
  ]
}